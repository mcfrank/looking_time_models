{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'granch_utils.lesioned_sim' from '/Users/caoanjie/Desktop/projects/looking_time_models/02_pyGRANCH/granch_utils/lesioned_sim.py'>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import pyro\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "import importlib\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from granch_utils import init_model_tensor, main_sim_tensor, lesioned_sim, compute_prob_tensor, init_params_tensor, num_stab_help\n",
    "#importlib.reload(granch_utils)\n",
    "importlib.reload(num_stab_help)\n",
    "importlib.reload(init_model_tensor)\n",
    "importlib.reload(main_sim_tensor)\n",
    "importlib.reload(lesioned_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1370, -0.0549, -0.0583],\n",
      "        [ 0.1370, -0.0549, -0.0361],\n",
      "        [ 0.1370, -0.0549, -0.0139],\n",
      "        ...,\n",
      "        [ 0.3370,  0.1451,  0.0973],\n",
      "        [ 0.3370,  0.1451,  0.1195],\n",
      "        [ 0.3370,  0.1451,  0.1417]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/caoanjie/Desktop/projects/looking_time_models/02_pyGRANCH/granch_utils/init_model_tensor.py:292: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.23718131222523356' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  \n",
      "/Users/caoanjie/Desktop/projects/looking_time_models/02_pyGRANCH/granch_utils/init_model_tensor.py:292: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.04527011282577964' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  \n",
      "/Users/caoanjie/Desktop/projects/looking_time_models/02_pyGRANCH/granch_utils/init_model_tensor.py:292: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.04173522565364221' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 2 and 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/caoanjie/Desktop/projects/looking_time_models/02_pyGRANCH/mini.ipynb Cell 2\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/caoanjie/Desktop/projects/looking_time_models/02_pyGRANCH/mini.ipynb#W1sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m params\u001b[39m.\u001b[39madd_lp_epsilon()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/caoanjie/Desktop/projects/looking_time_models/02_pyGRANCH/mini.ipynb#W1sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m params\u001b[39m.\u001b[39madd_priors()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/caoanjie/Desktop/projects/looking_time_models/02_pyGRANCH/mini.ipynb#W1sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m res \u001b[39m=\u001b[39m main_sim_tensor\u001b[39m.\u001b[39;49mgranch_main_simulation(params, tensor_model, tensor_stimuli[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/caoanjie/Desktop/projects/looking_time_models/02_pyGRANCH/mini.ipynb#W1sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39m#res = lesioned_sim.granch_no_learning_simulation(params, tensor_model, tensor_stimuli[0])\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/caoanjie/Desktop/projects/looking_time_models/02_pyGRANCH/mini.ipynb#W1sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m \u001b[39m#res = lesioned_sim.granch_no_noise_simulation(params, tensor_model, tensor_stimuli[0])\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/caoanjie/Desktop/projects/looking_time_models/02_pyGRANCH/mini.ipynb#W1sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m pd\u001b[39m.\u001b[39mset_option(\u001b[39m'\u001b[39m\u001b[39mdisplay.max_rows\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/projects/looking_time_models/02_pyGRANCH/granch_utils/main_sim_tensor.py:45\u001b[0m, in \u001b[0;36mgranch_main_simulation\u001b[0;34m(params, model, stimuli)\u001b[0m\n\u001b[1;32m     40\u001b[0m model\u001b[39m.\u001b[39mcur_posterior \u001b[39m=\u001b[39m current_posterior     \n\u001b[1;32m     43\u001b[0m \u001b[39m# this will currently work for only single feature    \u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[39m# in the tensor mode we don't need to iterate through possibilities anymore\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m model\u001b[39m.\u001b[39mps_likelihood \u001b[39m=\u001b[39m compute_prob_tensor\u001b[39m.\u001b[39;49mscore_likelihood(model, params, hypothetical_obs\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     46\u001b[0m model\u001b[39m.\u001b[39mps_posteriror \u001b[39m=\u001b[39m compute_prob_tensor\u001b[39m.\u001b[39mscore_posterior(model, params, hypothetical_obs\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     47\u001b[0m model\u001b[39m.\u001b[39mps_kl \u001b[39m=\u001b[39m compute_prob_tensor\u001b[39m.\u001b[39mkl_div(model\u001b[39m.\u001b[39mps_posteriror, model\u001b[39m.\u001b[39mcur_posterior)\n",
      "File \u001b[0;32m~/Desktop/projects/looking_time_models/02_pyGRANCH/granch_utils/compute_prob_tensor.py:68\u001b[0m, in \u001b[0;36mscore_likelihood\u001b[0;34m(model, params, hypothetical_obs)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39m# needs to be changed when incorporating multiple feature\u001b[39;00m\n\u001b[1;32m     67\u001b[0m current_obs \u001b[39m=\u001b[39m current_obs\u001b[39m.\u001b[39mflatten(start_dim \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m)\n\u001b[0;32m---> 68\u001b[0m obs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat([current_obs\u001b[39m.\u001b[39;49mrepeat(ps_obs\u001b[39m.\u001b[39;49msize()[\u001b[39m0\u001b[39;49m], \u001b[39m1\u001b[39;49m), ps_obs\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m1\u001b[39;49m)], dim \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     69\u001b[0m z_ij_collapse_dim \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     70\u001b[0m y_dim \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 2 and 3"
     ]
    }
   ],
   "source": [
    "importlib.reload(main_sim_tensor)\n",
    "importlib.reload(lesioned_sim)\n",
    "importlib.reload(init_params_tensor)\n",
    "importlib.reload(compute_prob_tensor)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "BATCH_INFO = {\n",
    "    \"jitter_n\": 1, \n",
    "    \"total_batch_n\": 1, \n",
    "    \"jitter_mode\": \"sampling\"\n",
    "}\n",
    "\n",
    "GRID_INFO = {\n",
    "    \"grid_mu_start\": -4, \"grid_mu_end\": 4, \"grid_mu_step\": 20, \n",
    "    \"grid_sigma_start\": 0.001, \"grid_sigma_end\": 1.8, \"grid_sigma_step\": 20, \n",
    "    \"grid_y_start\": -4, \"grid_y_end\": 4, \"grid_y_step\": 20, \n",
    "    \"grid_epsilon_start\": 0.000001, \"grid_epsilon_end\": 1, \"grid_epsilon_step\": 20, \n",
    "    \"hypothetical_obs_grid_n\": 10\n",
    "}\n",
    "\n",
    "\n",
    "BATCH_GRID_INFO = num_stab_help.get_batch_grid(BATCH_INFO, GRID_INFO)\n",
    "\n",
    "PRIOR_INFO = {\n",
    "    \"mu_prior\": 0,  \n",
    "    \"V_prior\": 1, \n",
    "    \"alpha_prior\": 3, \n",
    "    \"beta_prior\": 1, \n",
    "    \"epsilon\": 0.0001, \"mu_epsilon\":0.0001, \"sd_epsilon\": 0.0001, \n",
    "    \"hypothetical_obs_grid_n\": 10, \n",
    "    \"world_EIGs\": 0.0001, \"max_observation\": 500\n",
    "}\n",
    "\n",
    "tensor_stimuli = num_stab_help.sample_spore_experiment(pair_each_stim = 1, n_feature=3)\n",
    "\n",
    "tensor_model =  init_model_tensor.granch_model(PRIOR_INFO['max_observation'], tensor_stimuli[0])\n",
    "\n",
    "params = init_params_tensor.granch_params(\n",
    "                grid_mu =  BATCH_GRID_INFO[\"grid_mus\"][0].to(device),\n",
    "                grid_sigma = BATCH_GRID_INFO[\"grid_sigmas\"][0].to(device),\n",
    "                grid_y = BATCH_GRID_INFO[\"grid_ys\"][0].to(device),\n",
    "                grid_epsilon = BATCH_GRID_INFO[\"grid_epsilons\"][0].to(device),\n",
    "                hypothetical_obs_grid_n = PRIOR_INFO[\"hypothetical_obs_grid_n\"], \n",
    "                mu_prior = PRIOR_INFO[\"mu_prior\"],\n",
    "                V_prior = PRIOR_INFO[\"V_prior\"], \n",
    "                alpha_prior = PRIOR_INFO[\"alpha_prior\"], \n",
    "                beta_prior = PRIOR_INFO[\"beta_prior\"],\n",
    "                epsilon  = PRIOR_INFO[\"epsilon\"], \n",
    "                mu_epsilon = PRIOR_INFO[\"mu_epsilon\"], \n",
    "                sd_epsilon = PRIOR_INFO[\"sd_epsilon\"], \n",
    "                world_EIGs = PRIOR_INFO[\"world_EIGs\"],\n",
    "                max_observation = PRIOR_INFO[\"max_observation\"], \n",
    "                forced_exposure_max= np.nan)\n",
    "        \n",
    "            # add the various different cached bits\n",
    "params.add_meshed_grid()\n",
    "params.add_lp_mu_sigma()\n",
    "params.add_y_given_mu_sigma()\n",
    "params.add_lp_epsilon()\n",
    "params.add_priors()\n",
    "\n",
    "res = main_sim_tensor.granch_main_simulation(params, tensor_model, tensor_stimuli[0])\n",
    "#res = lesioned_sim.granch_no_learning_simulation(params, tensor_model, tensor_stimuli[0])\n",
    "#res = lesioned_sim.granch_no_noise_simulation(params, tensor_model, tensor_stimuli[0])\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "#print(res.behavior)\n",
    "#main_sim_tensor.granch_main_simulation(PRIOR_INFO, tensor_model, tensor_stimuli)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0680, -0.1684,  0.9000],\n",
       "        [ 0.0680, -0.1684,  0.9222],\n",
       "        [ 0.0680, -0.1684,  0.9444],\n",
       "        ...,\n",
       "        [ 0.2680,  0.0316,  1.0556],\n",
       "        [ 0.2680,  0.0316,  1.0778],\n",
       "        [ 0.2680,  0.0316,  1.1000]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_stim =  tensor_stimuli[0].stimuli_sequence\n",
    "noise_epsilon = 0.01\n",
    "hypothetical_obs_grid_n = 3\n",
    "#torch.linspace((test_stim[0] - noise_epsilon), (test_stim[0] + noise_epsilon, 3))\n",
    "        \n",
    "\n",
    "import torch\n",
    "\n",
    "a = torch.tensor([0.1680, -0.0684, 1], dtype=torch.float64)\n",
    "\n",
    "num_points = 10\n",
    "\n",
    "# Create a list of tensors, each containing the linspace for one dimension\n",
    "expanded_tensors = [torch.linspace(val - 0.1, val + 0.1, num_points) for val in a]\n",
    "\n",
    "# Stack the list of tensors to get the final expanded tensor\n",
    "expanded_tensor = torch.stack(expanded_tensors, dim=1).t()\n",
    "\n",
    "\n",
    "d1 = expanded_tensor[0]\n",
    "d2 = expanded_tensor[1]\n",
    "d3 = expanded_tensor[2]\n",
    "\n",
    "grid_1, grid_2, grid_3= torch.meshgrid(d1, d2, d3)\n",
    "\n",
    "# Stack the grids to form tensor C\n",
    "all_possible_obs = torch.stack((grid_1, grid_2, grid_3), dim=-1).view(-1, 3)\n",
    "\n",
    "all_possible_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/caoanjie/Desktop/projects/looking_time_models/02_pyGRANCH/mini.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/caoanjie/Desktop/projects/looking_time_models/02_pyGRANCH/mini.ipynb#X10sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mfor\u001b[39;00m idx, indices \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(indices_combinations):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/caoanjie/Desktop/projects/looking_time_models/02_pyGRANCH/mini.ipynb#X10sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mfor\u001b[39;00m col, row \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(indices):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/caoanjie/Desktop/projects/looking_time_models/02_pyGRANCH/mini.ipynb#X10sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         expanded_tensor[idx, col] \u001b[39m=\u001b[39m original_tensor[row, col]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/caoanjie/Desktop/projects/looking_time_models/02_pyGRANCH/mini.ipynb#X10sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# Print the expanded tensor\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/caoanjie/Desktop/projects/looking_time_models/02_pyGRANCH/mini.ipynb#X10sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mprint\u001b[39m(expanded_tensor)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([27, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create tensors A and B\n",
    "A = torch.tensor([1, 2, 3])\n",
    "B = torch.tensor([4, 5, 6])\n",
    "C = torch.tensor([7, 8, 9])\n",
    "\n",
    "# Create all combinations using torch.meshgrid()\n",
    "grid_A, grid_B, grid_C= torch.meshgrid(A,B,C)\n",
    "\n",
    "# Stack the grids to form tensor C\n",
    "D = torch.stack((grid_A, grid_B, grid_C), dim=-1)\n",
    "\n",
    "#print(D)\n",
    "\n",
    "# Reshape tensor C to 2D if needed\n",
    "D = D.view(-1, 3)\n",
    "\n",
    "# Print the resulting tensor C\n",
    "print(D.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "torch.meshgrid: Expected 0D or 1D tensor in the tensor list but got:  3  5\n 3  6\n 4  5\n 4  6\n[ torch.LongTensor{4,2} ]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/caoanjie/Desktop/projects/looking_time_models/02_pyGRANCH/mini.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/caoanjie/Desktop/projects/looking_time_models/02_pyGRANCH/mini.ipynb#X12sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m B \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([\u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/caoanjie/Desktop/projects/looking_time_models/02_pyGRANCH/mini.ipynb#X12sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m C \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([\u001b[39m5\u001b[39m, \u001b[39m6\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/caoanjie/Desktop/projects/looking_time_models/02_pyGRANCH/mini.ipynb#X12sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m result \u001b[39m=\u001b[39m combine_tensors(A, B, C)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/caoanjie/Desktop/projects/looking_time_models/02_pyGRANCH/mini.ipynb#X12sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# Print the resulting tensor\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/caoanjie/Desktop/projects/looking_time_models/02_pyGRANCH/mini.ipynb#X12sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mprint\u001b[39m(result)\n",
      "\u001b[1;32m/Users/caoanjie/Desktop/projects/looking_time_models/02_pyGRANCH/mini.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/caoanjie/Desktop/projects/looking_time_models/02_pyGRANCH/mini.ipynb#X12sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m left \u001b[39m=\u001b[39m combine_tensors(\u001b[39m*\u001b[39mtensors[:half])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/caoanjie/Desktop/projects/looking_time_models/02_pyGRANCH/mini.ipynb#X12sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m right \u001b[39m=\u001b[39m combine_tensors(\u001b[39m*\u001b[39mtensors[half:])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/caoanjie/Desktop/projects/looking_time_models/02_pyGRANCH/mini.ipynb#X12sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mreturn\u001b[39;00m combine_tensors(left, right)\n",
      "\u001b[1;32m/Users/caoanjie/Desktop/projects/looking_time_models/02_pyGRANCH/mini.ipynb Cell 6\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/caoanjie/Desktop/projects/looking_time_models/02_pyGRANCH/mini.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m tensors[\u001b[39m0\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/caoanjie/Desktop/projects/looking_time_models/02_pyGRANCH/mini.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(tensors) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/caoanjie/Desktop/projects/looking_time_models/02_pyGRANCH/mini.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m# Combine two tensors using broadcasting\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/caoanjie/Desktop/projects/looking_time_models/02_pyGRANCH/mini.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mstack(torch\u001b[39m.\u001b[39;49mmeshgrid(\u001b[39m*\u001b[39;49mtensors), dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/caoanjie/Desktop/projects/looking_time_models/02_pyGRANCH/mini.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/caoanjie/Desktop/projects/looking_time_models/02_pyGRANCH/mini.ipynb#X12sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m# Recursively combine N tensors by reducing them to two at a time\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/caoanjie/Desktop/projects/looking_time_models/02_pyGRANCH/mini.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     half \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(tensors) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/torch/functional.py:489\u001b[0m, in \u001b[0;36mmeshgrid\u001b[0;34m(indexing, *tensors)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmeshgrid\u001b[39m(\u001b[39m*\u001b[39mtensors, indexing: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Tensor, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m]:\n\u001b[1;32m    397\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Creates grids of coordinates specified by the 1D inputs in `attr`:tensors.\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \n\u001b[1;32m    399\u001b[0m \u001b[39m    This is helpful when you want to visualize data over some\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    487\u001b[0m \n\u001b[1;32m    488\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 489\u001b[0m     \u001b[39mreturn\u001b[39;00m _meshgrid(\u001b[39m*\u001b[39;49mtensors, indexing\u001b[39m=\u001b[39;49mindexing)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/torch/functional.py:504\u001b[0m, in \u001b[0;36m_meshgrid\u001b[0;34m(indexing, *tensors)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[39m# Continue allowing call of old method that takes no indexing\u001b[39;00m\n\u001b[1;32m    500\u001b[0m \u001b[39m# kwarg for forward compatibility reasons.\u001b[39;00m\n\u001b[1;32m    501\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m    502\u001b[0m \u001b[39m# Remove this two weeks after landing.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m kwargs \u001b[39m=\u001b[39m {} \u001b[39mif\u001b[39;00m indexing \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mindexing\u001b[39m\u001b[39m'\u001b[39m: indexing}\n\u001b[0;32m--> 504\u001b[0m \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39;49mmeshgrid(tensors, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: torch.meshgrid: Expected 0D or 1D tensor in the tensor list but got:  3  5\n 3  6\n 4  5\n 4  6\n[ torch.LongTensor{4,2} ]"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
