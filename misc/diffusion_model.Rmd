---
title: "Ratcliff & Rouder (1998) diffusion model"
author: "anjie"
date: "4/8/2021"
output: html_document
---
```{r}
library(tidyverse)
library(here)
library(rtdists)
```

nothing fancy just trying my best to understand this: 
https://cran.r-project.org/web/packages/rtdists/vignettes/reanalysis_rr98.html#description-of-the-experiment

# get familiar with the data

description: 
> In the experiment, three participants were asked to decide whether the overall brightness of pixel arrays displayed on a computer monitor was “high” or “low”. To this end, the number of white versus black pixels (i.e., the brightness strength) was manipulated in 33 levels from 0% white pixels (level 0) to 100% white pixels (level 32). In addition, instruction manipulated speed and accuracy between blocks. In total, each participant contributed around 4000 trials per instruction condition.


```{r}
data(rr98)

d <- rr98[!rr98$outlier,]
d
```

first look at the effect of strength on speed / accuracy 

```{r}
d %>% 
  group_by(id, strength, instruction) %>% 
  summarise(
    rt = mean(rt),
    prop_dark_response = mean(response == "dark")
  ) %>% 
  ggplot(aes(x = strength, 
             y = prop_dark_response, 
             color = instruction)) + 
  geom_point(alpha = .5) + 
  geom_line() + 
  facet_wrap(~id)
  
```

look at the distribution of rt 

looks like when participants were asked to judge accuracy they spent longer time when the strength is mid-way, which makes sense. 
```{r}
d %>% 
  ggplot(aes(x = strength, 
             y = rt))+ 
  geom_point(alpha = .2) + 
  facet_grid(id ~ instruction)
```

the tutorial also does some fancy binning stuff, skipping for now 

# diffusion model analysis 

```{r}
# binning snippet 
bins <- c(-0.5, 10.5, 13.5, 16.5, 19.5, 32.5)
d$strength_bin <- cut(d$strength, breaks = bins, include.lowest = TRUE)
levels(d$strength_bin) <- as.character(1:7)

d_nested <- d %>% 
  group_by(id, instruction) %>% 
  nest()

d_nested
```
function specification: https://www.rdocumentation.org/packages/rtdists/versions/0.11-2/topics/Diffusion

>Density, distribution function, quantile function, and random generation for the Ratcliff diffusion model with following parameters: a (threshold separation), z (starting point), v (drift rate), t0 (non-decision time/response time constant), d (differences in speed of response execution), sv (inter-trial-variability of drift), st0 (inter-trial-variability of non-decisional components), sz (inter-trial-variability of relative starting point), and s (diffusion constant). Note that the parameterization or defaults of non-decision time variability st0 and diffusion constant s differ from what is often found in the literature and that the parameterization of z and sz have changed compared to previous versions (now absolute and not relative).

fitting the full diffusion model to each instruction condition which results in 10 parameter per participant and instruction condition
- 5 drift rate v: one per strength bin 
- 1 boundary separation a(in RR, the two response boundaries are the two response options dark and light)
- 1 non-decision time t0 (non-decision time or response time constant (in seconds). Lower bound for the duration of all non-decisional processes (encoding and response execution). Typical range: 0.1 < t0 < 0.5)
- 1 drift rate variability sv (inter-trial-variability of drift)
- 1 start point z (version different: now absolute; previous relative)
- 1 start point variability 

> For this, we simply need to have a wrapper function which returns us the negative summed log-likelihood of the data (i.e., RTs and corresponding responses) given a set of parameters. We need the negativ sum because most optimization function minimize whereas we want to obtain the maximum likelihood value. [???]

```{r}

objective_diffusion_separate <- function(pars, rt, response, drift, ...) {
  
  non_v_pars <- grep("^v", names(pars), invert = TRUE, value = TRUE)
  base_par <- length(non_v_pars)  # number of non-drift parameters
  densities <- vector("numeric", length(rt))
  
  # loop through different value of drift 
  for (i in seq_along(levels(drift))) {
    densities[drift == levels(drift)[i]] <- 
      ddiffusion(
        
        rt[drift == levels(drift)[i]], 
        #a vector of RTs. 
        
        response=response[drift == levels(drift)[i]], 
        #character vector. Which response boundary should be tested? Possible values are c("upper", "lower"),           possibly abbreviated and "upper" being the default. Alternatively, a numeric vector with values              1=lower and 2=upper. For convenience, response is converted via as.numeric also allowing factors             (see examples). Ignored if the first argument is a data.frame.

          
        a=pars["a"], 
       # threshold separation. Amount of information that is considered for a decision. Large values indicate           a conservative decisional style. Typical range: 0.5 < a < 2


        t0=pars["t0"],  
       #non-decision time or response time constant (in seconds). Lower bound for the duration of all                non-decisional processes (encoding and response execution). Typical range: 0.1 < t0 < 0.5


        sv=pars["sv"],
       # intertrial variability of the drift rate 
       
         sz=if ("sz" %in% non_v_pars) pars["sz"] else 0.1,
       # intertrial variability of starting point 
       
         z=if ("z" %in% non_v_pars) pars["z"]*pars["a"] else 0.5*pars["a"],
       # starting point. Indicator of an a priori bias in decision making. When the relative starting point z         deviates from 0.5*a, the amount of information necessary for a decision differs between response             alternatives. Default is 0.5*a (i.e., no bias).

          st0=if ("st0" %in% non_v_pars) pars["st0"] else 0, 
       # inter-trial-variability of non-decisional components. 
       
          v=pars[base_par+i])
    # drift rate. Average slope of the information accumulation process. The drift gives information about         the speed and direction of the accumulation of information. Large (absolute) values of drift indicate a       good performance. If received information supports the response linked to the upper threshold the sign         will be positive and vice versa. Typical range: -5 < v < 5
    
    
  }
  if (any(densities == 0)) return(1e6) #??? what is this 
  return(-sum(log(densities)))
}
```


then we need to find a set of starting value. strategy is trying random starting values untill a set of valid is found (??what does it mean for a set to be valid??) 

```{r}
get_start <- function(base_par, n_drift = 5) {
  start1 <- c(
    a = runif(1, 0.5, 3),
    a_1 = runif(1, 0.5, 3), 
    a_2 = runif(1, 0.5, 3),
    t0 = runif(1, 0, 0.5), 
    z = runif(1, 0.4, 0.6), 
    sz = runif(1, 0, 0.5),
    sv = runif(1, 0, 0.5),
    st0 = runif(1, 0, 0.5),
    d = rnorm(1, 0, 0.05)
  )
  start2 <- sort(rnorm(n_drift), decreasing = FALSE)
  names(start2) <- paste0("v_", seq_len(n_drift))
  c(start1[base_par], start2)
}

# function that tries different random start values until it works:
ensure_fit <- 
  function(data, start_function, objective_function, 
           base_pars, n_drift = 5, n_fits = 1, 
           lower = c(rep(0, length(base_pars)), -Inf,
                     rep(-Inf,length(start_function(base_pars))-length(base_pars)))) {
    best_fit <- list(objective = 1e+06)
  for (i in seq_len(n_fits)) {
    start_ll <- 1e+06
    #browser()
    while(start_ll == 1e+06) {
      start <- start_function(base_pars, n_drift=n_drift)
      start_ll <- objective_function(start, 
                                     rt = data$rt, response = data$response_num, 
                                     drift = factor(data$strength_bin, seq_len(n_drift)), 
                                     instruction = data$instruction)
    }
    cat("\nstart fitting.\n") # just for information to see if it is stuck
    
    fit <- nlminb(start, objective_function, 
                  rt = data$rt, response = data$response_num, 
                  drift = factor(data$strength_bin, seq_len(n_drift)), 
                  instruction = data$instruction,
                  lower = lower)
    
    if (fit$objective < best_fit$objective) best_fit <- fit
  }
  out <- as.data.frame(t(unlist(best_fit[1:3])))
  colnames(out) <- sub("par.", "", colnames(out))
  out
}
```

```{r}
library(tidyverse)
fit_diffusion <- d_nested
fit_diffusion$fit <- 
  parallel::mclapply(d_nested$data, function(x) 
    ensure_fit(data = x, start_function = get_start,
               objective_function = objective_diffusion_separate, 
               base_pars = c("a", "t0", "sv", "sz", "z")),  
    mc.cores = 2)
fit_diffusion <- unnest(fit_diffusion, fit)
```

```{r}
fit_diffusion
```

## graphical model fit 
```{r}
pars_separate_l <- fit_diffusion %>% gather("strength_bin", "v", starts_with("v"))
pars_separate_l$strength_bin <- factor(substr(pars_separate_l$strength_bin, 3,3), 
                                       levels = as.character(seq_len(length(bins)-1)))

pars_separate_l
```



