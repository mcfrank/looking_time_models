---
title: "Model behaviors investigation"
author: "anjie"
date: "11/18/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(here)
library(matrixStats)
library(partitions)
library(tictoc)
library(LaplacesDemon)
library(patchwork)


source(here("helper/make_scheme_and_params.R"))
source(here("helper/initialization.R"))
source(here("helper/probability_computations.R"))
source(here("misc/model_diagnosis/main_simulation_with_visualization.R"))


```


# Understanding dishabituation patterns 
```{r}
alpha_epsilons = c(1)
beta_epsilons = c(10)
alpha_priors = c(1)
beta_priors = c(100)
noise_parameters = c(0)
world_EIGs = c(0.001)
max_observation = 100

model_params <- set_model_params(alpha_priors, beta_priors, 
                alpha_epsilons, beta_epsilons, 
                noise_parameters, world_EIGs, max_observation)


# set stimuli-related parameters 
features_df <- tibble(
  n_features = c(1), 
  on_features_n = c(1)
)
sequence_scheme = c("BBBBBBB")

stims_df <- set_stim_params(sequence_scheme, features_df)


full_params_df <- make_simulation_params(n_sim = 150,
                                        model_params, 
                                        stims_df)

```

```{r}

 main_simulation(params = full_params_df %>% filter(sequence_scheme == "BBBBBBB", sub_id == 1)%>% nest() %>% unnest(), 
                visualization = TRUE)

 
```


```{r}
single_sim <- main_simulation(params = full_params_df %>% filter(sequence_scheme == "BBBBBBB", sub_id == 1)%>% nest() %>% unnest(), 
                visualization = FALSE, detailed_post = TRUE)
```

```{r}
single_sim[[1]] %>% View()
```

```{r}
single_sim[[1]] %>% 
    group_by(stimulus_idx) %>% 
    summarise(sample_n = n()) %>% 
    ggplot(aes(x = stimulus_idx, y = sample_n)) + 
    geom_point()

single_sim[[1]] %>% 
  ggplot(aes(x = t, y = EIG, color = as.factor(stimulus_idx))) +
  geom_point()
```
#ok so what's up with t = 21 and t = 22

```{r}
single_sim[[1]] %>% 
  filter(stimulus_idx %in% c(7)) 
```

```{r}
# true posterior at t = 26
# hypothetical posterior when obs is false 
single_sim[[2]][[26]][[1]]$posterior 
single_sim[[4]][[26]]$posterior

kl_div(single_sim[[4]][[26]]$posterior, single_sim[[2]][[26]][[1]]$posterior)



# true posterior at t = 27
# hypothetical posterior when obs is false 
single_sim[[2]][[27]][[1]]$posterior 
single_sim[[4]][[27]]$posterior


kl_div(single_sim[[4]][[27]]$posterior, single_sim[[2]][[27]][[1]]$posterior)


```

```{r}
single_sim[[2]][[27]][[1]]
```


the change honestly looks quite gradual and reasonable, so now we need to check the EIG calculation on t = 17 and t = 18. 
```{r}
#WITH TRUE OBSERVATION
single_sim[[3]][[26]]

#WITH FALSE OBSERVATION
single_sim[[4]][[26]]

# GET kl 
kl_div(single_sim[[3]][[26]]$posterior,
                              single_sim[[2]][[26]][[1]]$posterior)

kl_div(single_sim[[4]][[26]]$posterior,
                              single_sim[[2]][[26]][[1]]$posterior)


#WITH TRUE OBSERVATION
single_sim[[3]][[27]]

#WITH FALSE OBSERVATION
single_sim[[4]][[27]]

# GET kl 
kl_div(single_sim[[3]][[27]]$posterior,
                              single_sim[[2]][[27]][[1]]$posterior)

kl_div(single_sim[[4]][[27]]$posterior,
                              single_sim[[2]][[27]][[1]]$posterior)
```


```{r}

#abnormal
ab_x <- single_sim[[4]][[27]]$posterior
ab_y <- single_sim[[2]][[27]][[1]]$posterior
ab_kl <- ab_x * log(ab_x/ab_y)

n_x <- single_sim[[4]][[26]]$posterior
n_y <- single_sim[[2]][[26]][[1]]$posterior
n_kl <- n_x * log(n_x/n_y)

comp_df <- 
  tibble(
    ab_x = ab_x,
    ab_y = ab_y, 
    ab_kl = ab_kl, 
    n_x = n_x, 
    n_y = n_y, 
    n_kl = n_kl
  ) %>% 
  mutate(id = row_number()) %>% 
  pivot_longer(cols = !contains("id"), 
               names_to = "type", 
               values_to = "value") %>% 
  separate(type, into = c("categories", "value_type"), 
           sep = "_") %>% 
  mutate(
    print_categories = if_else(categories =="ab", "t = 27", "t = 26"), 
    print_value_type = case_when(
      value_type == "x" ~ "1_false_obs", 
      value_type == "y" ~ "2_posterior", 
      TRUE ~ value_type
    )
  )

comp_df %>% 
  #filter(print_value_type == "kl") %>% 
  ggplot(aes(x = id, y = value, color = print_value_type)) + 
  geom_point()+
  facet_grid(print_value_type~print_categories, scales = "free")


comp_df %>% 
  filter(value_type == "kl")

```

i don't understand why it is so small. maybe another way to do it is to do it the log way 
```{r}

# sum(x * log(x/y))
# logSumExp(log(X) + (log(X) - log(Y)))

# might just be a minor bug 
log(ab_x) == single_sim[[4]][[27]]$log_posterior
log(n_x) == single_sim[[4]][[26]]$log_posterior

log(ab_y) == single_sim[[2]][[27]][[1]]$log_posterior
log(n_y) == single_sim[[2]][[26]][[1]]$log_posterior



```

```{r}

(single_sim[[1]]$EIG)[14:28] %>% 
  plot()
```



```{r}
ab_sum = 0
n_sum = 0

ab_acc <- list()
n_acc <- list()
for(i in 1:length(ab_kl)){
  ab_sum <- ab_sum + ab_kl[i]
  n_sum <- n_sum + n_kl[i]
  ab_acc[i] <- ab_sum 
  n_acc[i] <- n_sum 

}


```




```{r}
ab_x[[1]]
n_x[[1]]

ab_y[[1]]
n_y[[1]]

ab_kl[[1]]
n_kl[[1]]
```



```{r}
ab_x <- single_sim[[4]][[27]]$posterior
ab_y <- single_sim[[2]][[27]][[1]]$posterior
ab_kl <- ab_x * log(ab_x/ab_y)

n_x <- single_sim[[4]][[26]]$posterior
n_y <- single_sim[[2]][[26]][[1]]$posterior
n_kl <- n_x * log(n_x/n_y)

comp_df <- 
  tibble(
    ab_x = ab_x,
    ab_y = ab_y, 
    ab_kl = ab_kl, 
    n_x = n_x, 
    n_y = n_y, 
    n_kl = n_kl
  ) %>% 
  mutate(id = row_number()) %>% 
  pivot_longer(cols = !contains("id"), 
               names_to = "type", 
               values_to = "value") %>% 
  separate(type, into = c("categories", "value_type"), 
           sep = "_") 

comp_df %>% 
  filter(id !=1) %>% 
  ggplot(aes(x = id, y = value, color = value_type)) + 
  geom_point()+
  facet_grid(value_type~categories, scales = "free")
```



```{r}
ab_kl[2]
n_kl[2]

ab_x[2]
ab_y[2]

n_x[2]
n_y[2]

single_sim[[4]][[27]]
```





i wonder if this is a property of the KL (how it interacts with the prior)
goal: construct a toy example with beta count and how it changes the KL as evidence accumulate 
```{r}
x <- dbeta(seq(0.01, 0.99, 0.2), 1, 10) / sum(dbeta(seq(0.01, 0.99, 0.2), 1, 10))
y <- dbeta(seq(0.01, 0.99, 0.2), 1, 9) / sum(dbeta(seq(0.01, 0.99, 0.2), 1, 9))

t <- rbind(x, y)

philentropy::KL(t)


get_kl <- function(prior_alpha, prior_beta, obs = FALSE){
  
  prior <- dbeta(seq(0.01, 0.99, 0.1), prior_alpha, prior_beta) / sum(dbeta(seq(0.01, 0.99, 0.1), 
                                                                            prior_alpha, 
                                                                            prior_beta))
  
  if(obs){
    post_alpha = prior_alpha + 1
    post_beta = prior_beta
  }else{
    post_alpha = prior_alpha 
    post_beta = prior_beta + 1
  }
  
  post <- dbeta(seq(0.01, 0.99, 0.1), post_alpha, post_beta) / sum(dbeta(seq(0.01, 0.99, 0.1), 
                                                                            post_alpha, 
                                                                            post_beta))
  
  return(philentropy::KL(rbind(prior, post), unit = "log"))
  
}


```

```{r}
prior_df <- tibble(
  prior_alpha = rep(100, 200), # to mimic accumulating true observation 
  prior_beta = seq(1, 200)
)

false_df <- pmap_df(prior_df, get_kl, obs = FALSE) %>% 
  rename(false_obs = `kullback-leibler`)
true_df <- pmap_df(prior_df, get_kl, obs = TRUE) %>% 
  rename(true_obs = `kullback-leibler`)

full_df <- bind_cols(prior_df, false_df, true_df) %>% 
  pivot_longer(cols = c("false_obs", "true_obs"), names_to = "value_type", values_to = "value")
  
full_df %>%   
  ggplot(aes(x = prior_beta, y = value, color = value_type)) + 
  geom_point()

```
```{r}
prior_df <- tibble(
  prior_alpha = seq(1, 1500), # to mimic accumulating true observation 
  prior_beta = rep(100, 1500)
)

false_df <- pmap_df(prior_df, get_kl, obs = FALSE) %>% 
  rename(false_obs = `kullback-leibler`)
true_df <- pmap_df(prior_df, get_kl, obs = TRUE) %>% 
  rename(true_obs = `kullback-leibler`)

full_df <- bind_cols(prior_df, false_df, true_df) %>% 
  pivot_longer(cols = c("false_obs", "true_obs"), names_to = "value_type", values_to = "value")
  
full_df %>%   
  #ilter(prior_alpha > 1000) %>% 
  ggplot(aes(x = prior_alpha, y = value, color = value_type)) + 
  geom_point()
```


ok now really needs goes into the posterior distribution to see if it is going wrong 
```{r}

```












```{r}
all_sims_res %>% 
  rowwise() %>% 
  mutate(sequence_length = nchar(as.character(sequence_scheme)), 
         item_type = case_when(
           sequence_length == 2 & sequence_scheme == "BD" & stimulus_idx == 2 ~ "deviant", 
           sequence_length == 3 & sequence_scheme == "BBD" &stimulus_idx == 3 ~ "deviant", 
           sequence_length == 4 & sequence_scheme == "BBBD" & stimulus_idx == 4 ~ "deviant", 
           sequence_length == 5 & sequence_scheme == "BBBBD" & stimulus_idx == 5 ~ "deviant", 
            sequence_length == 6 & sequence_scheme == "BBBBBD" & stimulus_idx == 6 ~ "deviant",
           TRUE ~ "background"
         )) %>% 
  ggplot(aes(x = t, y = EIG, color = item_type, group = sequence_scheme)) + 
  geom_point() + 
  geom_line() + 
  facet_wrap(sequence_length~sequence_scheme)
  
```

# Understanding Complexity 
- things that might influence complexity effect: 
  - complexity representation: fixed length vector or vector length representing complexity 
  - prior: how likely feature is going to occur is going to have an influence on the "informativeness" of the feature appearing. 
      - try: a10b1, a1b1, a1b10, a10b10

needs 8 possible combinations, each has simple or complex, so 16 rows  
      
```{r}
alpha_epsilon = c(1)
beta_epsilon = c(10)
alpha_priors = c(1, 10)
beta_priors = c(1, 10)
noise_parameters = c(0)
world_EIG = c(0.001)
max_observation = 100
fixed_length_complexity = FALSE 
feature_space_n = 7
simple_feature_n = 1
complex_feature_n = 3
dissimilar_ratio = 1
#sequence_scheme = c("BDBBBB", "BBBDBB", "BBBBBD", "BBBBBB")

sequence_scheme = c("BBBBB")

complexity = c("simple", "complex") 
n <- 1 # doesn't perform as expected

fixed_length_params_df <- make_simulation_params(n = n,
                                         sequence_scheme, 
                                         complexity, 
                                         alpha_priors, 
                                         beta_priors, 
                                         alpha_epsilon, 
                                         beta_epsilon, 
                                         noise_parameters, 
                                         world_EIG, 
                                         max_observation, 
                                         fixed_length_complexity = TRUE, 
                                         feature_space_n, 
                                         simple_feature_n, 
                                         complex_feature_n, 
                                         dissimilar_ratio)



flex_length_params_df <- make_simulation_params(n = n,
                                         sequence_scheme, 
                                         complexity, 
                                         alpha_priors, 
                                         beta_priors, 
                                         alpha_epsilon, 
                                         beta_epsilon, 
                                         noise_parameters, 
                                         world_EIG, 
                                         max_observation, 
                                         fixed_length_complexity = FALSE, 
                                         feature_space_n, 
                                         simple_feature_n, 
                                         complex_feature_n, 
                                         dissimilar_ratio) 

# this is a temproary fix to get the right index for parameters

complexity_params <- bind_rows(fixed_length_params_df, flex_length_params_df) %>% 
  mutate(params_id = case_when(
    fixed_length_complexity ~ as.integer(params_id), 
    fixed_length_complexity == FALSE ~ as.integer(params_id) + as.integer(4)
  )) %>% 
  rowwise() %>% 
  mutate(n_features = ncol(stimuli_sequence$data[[1]]) - 1)
  
```



```{r}
  
all_sims_res_complexity <- complexity_params %>%
  group_by(params_id, sim_id) %>%
  nest() %>%
  mutate(sub_id = 1)
  mutate(results = map(data,
                       function(df) main_simulation(params = df))) %>%
  unnest(cols = c(data, results))
```


FALSE = flexible length complexity, 1 feature vs 3 feature 
TRUE = fixed length complexity, 6 FALSE 1 TRUE vs 4 FALSE 3 TRUE  

```{r}
all_sims_res_complexity %>% 
  mutate(
    param = paste0("a", alpha_prior, "b", beta_prior, "_", fixed_length_complexity)
  ) %>% 
  ggplot(aes(x = t, y = EIG, color = complexity)) + 
  geom_point()+
  geom_line()+
  facet_wrap(~param)
```
how does this translate to looking time sample? 

```{r}
n_sim = 50

complexity_params <- bind_rows(fixed_length_params_df, flex_length_params_df) %>% 
  mutate(params_id = case_when(
    fixed_length_complexity ~ as.integer(params_id), 
    fixed_length_complexity == FALSE ~ as.integer(params_id) + as.integer(4)
  )) %>% 
  rowwise() %>% 
  mutate(n_features = ncol(stimuli_sequence$data[[1]]) - 1)


sims_res_complexity_fs <- complexity_params %>%
  filter(alpha_prior == 1 & beta_prior == 10) %>% 
  left_join(expand_grid(sim_id = 1:2, params_id = c(2, 6), sub_id = 1:n_sim)) %>% 
  group_by(params_id, sim_id, sub_idn) %>%
  nest() %>%
  mutate(results = map(data,
                       function(df) main_simulation(params = df))) %>%
  unnest(cols = c(data, results))
```

```{r}
sims_res_complexity_fs %>% 
  mutate(params_info = paste0("a", alpha_prior, "b", beta_prior, "_", fixed_length_complexity)) %>% 
  group_by(params_id, params_info, sim_id, sub_id, stimulus_idx) %>% 
  summarise(sample_n = n()) %>% 
  filter(!is.na(stimulus_idx)) %>% 
  ggplot(aes(x = stimulus_idx, y = sample_n, color = as.factor(sim_id))) + 
  #geom_point() + 
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width = .2)) + 
  theme_classic()+
  facet_wrap(~params_info)
```


```{r}
sequence_scheme = c("BBBBBB", "BDBBBB", "BBBDBB", "BBBBBD")

complexity = c("simple", "complex") 

alpha_priors = c(1, 10)
beta_priors = c(1, 10)

fixed_length_params_df <- make_simulation_params(n = n,
                                         sequence_scheme, 
                                         complexity, 
                                         alpha_priors, 
                                         beta_priors, 
                                         alpha_epsilon, 
                                         beta_epsilon, 
                                         noise_parameters, 
                                         world_EIG, 
                                         max_observation, 
                                         fixed_length_complexity = TRUE, 
                                         feature_space_n, 
                                         simple_feature_n, 
                                         complex_feature_n, 
                                         dissimilar_ratio)



flex_length_params_df <- make_simulation_params(n = n,
                                         sequence_scheme, 
                                         complexity, 
                                         alpha_priors, 
                                         beta_priors, 
                                         alpha_epsilon, 
                                         beta_epsilon, 
                                         noise_parameters, 
                                         world_EIG, 
                                         max_observation, 
                                         fixed_length_complexity = FALSE, 
                                         feature_space_n, 
                                         simple_feature_n, 
                                         complex_feature_n, 
                                         dissimilar_ratio) 

# this is a temproary fix to get the right index for parameters

complexity_params <- bind_rows(fixed_length_params_df, flex_length_params_df) %>% 
  mutate(params_id = case_when(
    fixed_length_complexity ~ as.integer(params_id), 
    fixed_length_complexity == FALSE ~ as.integer(params_id) + as.integer(4)
  )) %>% 
  rowwise() %>% 
  mutate(n_features = ncol(stimuli_sequence$data[[1]]) - 1)


sims_res_complexity_fs_trajectory <- complexity_params %>%
  filter(alpha_prior == 1) %>% 
  filter(beta_prior == 10) %>% 
  left_join(expand_grid(sim_id = 1:8, params_id = c(2, 6), sub_id = 1:n_sim)) %>% 
  group_by(params_id, sim_id, sub_id) %>%
  nest() %>%
  mutate(results = map(data,
                       function(df) main_simulation(params = df))) %>%
  unnest(cols = c(data, results))
```

```{r}
sims_res_complexity_fs_trajectory
```


```{r}
sims_res_complexity_fs_trajectory %>% 
  mutate(params_info = paste0("a", alpha_prior, "b", beta_prior, "_", fixed_length_complexity)) %>% 
  group_by(params_id, sequence_scheme, params_info, sim_id, sub_id, stimulus_idx, complexity) %>% 
  summarise(sample_n = n()) %>% 
  filter(!is.na(stimulus_idx)) %>% 
  ggplot(aes(x = stimulus_idx, y = sample_n, color = complexity)) + 
  #geom_point() + 
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width = .2)) + 
  theme_classic()+
  facet_wrap(params_info~sequence_scheme)
```


- observation from behavioral data: very ambiguous complexity effect 

- model: 
  - start with simple case, BBBBB
  - see dishabituation's influence: BBBBD
  












# Playing with EIG decision 