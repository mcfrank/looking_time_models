{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'granch_utils.lesioned_sim' from '/Users/caoanjie/Desktop/projects/looking_time_models/02_pyGRANCH/granch_utils/lesioned_sim.py'>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import pyro\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "import importlib\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from granch_utils import init_model_tensor, main_sim_tensor, lesioned_sim, compute_prob_tensor, init_params_tensor, num_stab_help\n",
    "#importlib.reload(granch_utils)\n",
    "importlib.reload(num_stab_help)\n",
    "importlib.reload(init_model_tensor)\n",
    "importlib.reload(main_sim_tensor)\n",
    "importlib.reload(lesioned_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/caoanjie/Desktop/projects/looking_time_models/02_pyGRANCH/granch_utils/init_model_tensor.py:279: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.199' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  self.all_observations.loc[self.current_t]  = Normal(current_stimulus, noise_epsilon).sample().tolist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    stimulus_id       EIG Look_away\n",
      "0             0  0.486392     False\n",
      "1             0   0.45973     False\n",
      "2             0  0.306492     False\n",
      "3             0  0.168279     False\n",
      "4             0  0.087707     False\n",
      "..          ...       ...       ...\n",
      "495         NaN       NaN       NaN\n",
      "496         NaN       NaN       NaN\n",
      "497         NaN       NaN       NaN\n",
      "498         NaN       NaN       NaN\n",
      "499         NaN       NaN       NaN\n",
      "\n",
      "[500 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(main_sim_tensor)\n",
    "importlib.reload(lesioned_sim)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "BATCH_INFO = {\n",
    "    \"jitter_n\": 1, \n",
    "    \"total_batch_n\": 1, \n",
    "    \"jitter_mode\": \"sampling\"\n",
    "}\n",
    "\n",
    "GRID_INFO = {\n",
    "    \"grid_mu_start\": -4, \"grid_mu_end\": 4, \"grid_mu_step\": 20, \n",
    "    \"grid_sigma_start\": 0.001, \"grid_sigma_end\": 1.8, \"grid_sigma_step\": 20, \n",
    "    \"grid_y_start\": -4, \"grid_y_end\": 4, \"grid_y_step\": 20, \n",
    "    \"grid_epsilon_start\": 0.001, \"grid_epsilon_end\": 1.8, \"grid_epsilon_step\": 20, \n",
    "    \"hypothetical_obs_grid_n\": 10\n",
    "}\n",
    "\n",
    "\n",
    "BATCH_GRID_INFO = num_stab_help.get_batch_grid(BATCH_INFO, GRID_INFO)\n",
    "\n",
    "PRIOR_INFO = {\n",
    "    \"mu_prior\": 0,  \n",
    "    \"V_prior\": 3, \n",
    "    \"alpha_prior\": 1, \n",
    "    \"beta_prior\": 2, \n",
    "    \"epsilon\": 0.001, \"mu_epsilon\": 0.001, \"sd_epsilon\": 4, \n",
    "    \"hypothetical_obs_grid_n\": 10, \n",
    "    \"world_EIGs\": 0.0001, \"max_observation\": 500\n",
    "}\n",
    "\n",
    "tensor_stimuli = num_stab_help.sample_spore_experiment(1)\n",
    "\n",
    "tensor_model =  init_model_tensor.granch_model(PRIOR_INFO['max_observation'], tensor_stimuli[0])\n",
    "\n",
    "params = init_params_tensor.granch_params(\n",
    "                grid_mu =  BATCH_GRID_INFO[\"grid_mus\"][0].to(device),\n",
    "                grid_sigma = BATCH_GRID_INFO[\"grid_sigmas\"][0].to(device),\n",
    "                grid_y = BATCH_GRID_INFO[\"grid_ys\"][0].to(device),\n",
    "                grid_epsilon = BATCH_GRID_INFO[\"grid_epsilons\"][0].to(device),\n",
    "                hypothetical_obs_grid_n = PRIOR_INFO[\"hypothetical_obs_grid_n\"], \n",
    "                mu_prior = PRIOR_INFO[\"mu_prior\"],\n",
    "                V_prior = PRIOR_INFO[\"V_prior\"], \n",
    "                alpha_prior = PRIOR_INFO[\"alpha_prior\"], \n",
    "                beta_prior = PRIOR_INFO[\"beta_prior\"],\n",
    "                epsilon  = PRIOR_INFO[\"epsilon\"], \n",
    "                mu_epsilon = PRIOR_INFO[\"mu_epsilon\"], \n",
    "                sd_epsilon = PRIOR_INFO[\"sd_epsilon\"], \n",
    "                world_EIGs = PRIOR_INFO[\"world_EIGs\"],\n",
    "                max_observation = PRIOR_INFO[\"max_observation\"], \n",
    "                forced_exposure_max= np.nan)\n",
    "        \n",
    "            # add the various different cached bits\n",
    "params.add_meshed_grid()\n",
    "params.add_lp_mu_sigma()\n",
    "params.add_y_given_mu_sigma()\n",
    "params.add_lp_epsilon()\n",
    "params.add_priors()\n",
    "\n",
    "#res = main_sim_tensor.granch_main_simulation(params, tensor_model, tensor_stimuli[0])\n",
    "#res = lesioned_sim.granch_no_learning_simulation(params, tensor_model, tensor_stimuli[0])\n",
    "res = lesioned_sim.granch_no_noise_simulation(params, tensor_model, tensor_stimuli[0])\n",
    "\n",
    "print(res.behavior)\n",
    "#main_sim_tensor.granch_main_simulation(PRIOR_INFO, tensor_model, tensor_stimuli)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     j_i  stimulus_id stim_squence violation_type  epsilon  b_val  d_val  \\\n",
      "0      0            0       BBBBBB       identity   0.0001  0.116  0.223   \n",
      "1      0            1       BBBBBB       identity   0.0001  0.116  0.223   \n",
      "2      0            2       BBBBBB       identity   0.0001  0.116  0.223   \n",
      "3      0            3       BBBBBB       identity   0.0001  0.116  0.223   \n",
      "4      0            4       BBBBBB       identity   0.0001  0.116  0.223   \n",
      "..   ...          ...          ...            ...      ...    ...    ...   \n",
      "115   19            1       BBBBBB       identity   0.0001  0.116  0.223   \n",
      "116   19            2       BBBBBB       identity   0.0001  0.116  0.223   \n",
      "117   19            3       BBBBBB       identity   0.0001  0.116  0.223   \n",
      "118   19            4       BBBBBB       identity   0.0001  0.116  0.223   \n",
      "119   19            5       BBBBBB       identity   0.0001  0.116  0.223   \n",
      "\n",
      "     mu_prior  v_prior  alpha_prior  beta_prior  n_sample  \n",
      "0           0        1            1           1         1  \n",
      "1           0        1            1           1         2  \n",
      "2           0        1            1           1         4  \n",
      "3           0        1            1           1         1  \n",
      "4           0        1            1           1         1  \n",
      "..        ...      ...          ...         ...       ...  \n",
      "115         0        1            1           1         2  \n",
      "116         0        1            1           1         2  \n",
      "117         0        1            1           1         1  \n",
      "118         0        1            1           1         1  \n",
      "119         0        1            1           1         2  \n",
      "\n",
      "[120 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "d = pd.read_pickle(\"no_learning/09-17-11:31:45.831-spore-adult.pickle\")\n",
    "\n",
    "\n",
    "main_df = d.dropna(subset = [\"stimulus_id\"])\n",
    "counts = main_df.groupby(['j_i',  \"stimulus_id\", \"stim_squence\", \"violation_type\"]).agg({'epsilon': 'first', 'b_val': 'first', 'd_val': 'first', 'mu_prior' : 'first',\n",
    "                                                                                                                'mu_prior': 'first','v_prior': 'first','alpha_prior': 'first','beta_prior': 'first',\n",
    "      \n",
    "                                                                                              'epsilon': 'first'}).reset_index()\n",
    "        \n",
    "\n",
    "counts[\"n_sample\"] =  main_df.groupby([ 'j_i',  \"stimulus_id\", \"stim_squence\", \"violation_type\"], as_index=False).count()['Look_away']\n",
    "\n",
    "#d.groupby([\"j_i\",\"stimulus_id\", \"stim_squence\", \"violation_type\"], as_index=False).count()['Look_away']\n",
    "print(counts)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_names: ['09-17-11:31:59.294-spore-adult.pickle', '09-17-11:32:11.471-spore-adult.pickle', '09-17-11:32:07.314-spore-adult.pickle', '09-17-11:31:55.013-spore-adult.pickle', '09-17-11:31:57.712-spore-adult.pickle', '09-17-11:31:55.483-spore-adult.pickle', '09-17-11:31:49.310-spore-adult.pickle', '09-17-11:31:53.904-spore-adult.pickle', '09-17-11:31:46.328-spore-adult.pickle', '09-17-11:32:02.088-spore-adult.pickle', '09-17-11:32:04.979-spore-adult.pickle', '09-17-11:31:50.344-spore-adult.pickle', '09-17-11:32:01.602-spore-adult.pickle', '09-17-11:31:52.155-spore-adult.pickle', '09-17-11:32:04.506-spore-adult.pickle', '09-17-11:31:52.962-spore-adult.pickle', '09-17-11:32:09.242-spore-adult.pickle', '09-17-11:32:09.080-spore-adult.pickle', '09-17-11:32:10.192-spore-adult.pickle', '09-17-11:32:05.292-spore-adult.pickle']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def count_until_look_away(group):\n",
    "    return group['Look_away'].tolist().index(True) if True in group['Look_away'].tolist() else len(group)\n",
    "\n",
    "folder_path = \"no_learning/\"\n",
    "df_list = []\n",
    "\n",
    "# infant or adult runs\n",
    "paradigm = 'adult'\n",
    "\n",
    "# spore or unity\n",
    "stims = 'spore'\n",
    "\n",
    "# get list of file names\n",
    "file_names = [f for f in os.listdir(folder_path) if f.endswith('.pickle') and paradigm in f and stims in f]\n",
    "\n",
    "print(\"file_names:\", file_names[0:20])\n",
    "\n",
    "for idx, file_name in enumerate(file_names):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        try:\n",
    "            df = pd.read_pickle(file_path)\n",
    "            df[\"batch_id\"] = idx\n",
    "            df_list.append(df)\n",
    "        except:\n",
    "             print('error encountered for: ', file_path)\n",
    "             \n",
    "        main_df = pd.concat(df_list)\n",
    "        main_df = main_df.dropna(subset = [\"stimulus_id\"])\n",
    "        counts = main_df.groupby(['batch_id', 'j_i',  \"stimulus_id\", \"stim_squence\", \"violation_type\"]).agg({'epsilon': 'first', 'b_val': 'first', 'd_val': 'first', 'mu_prior' : 'first',\n",
    "                                                                                                                'mu_prior': 'first','v_prior': 'first','alpha_prior': 'first','beta_prior': 'first',\n",
    "                                                                                                    'epsilon': 'first'}).reset_index()\n",
    "        \n",
    "        counts[\"n_sample\"] =  main_df.groupby(['batch_id', 'j_i',  \"stimulus_id\", \"stim_squence\", \"violation_type\"], as_index=False).count()['Look_away']\n",
    "        #print(counts['n_sample'])\n",
    "        \n",
    "        counts.to_csv(\"no_noise\"+ \".csv\", mode = 'a', index=False, header=False)\n",
    "        df_list = []\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
