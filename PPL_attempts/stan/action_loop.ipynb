{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import arviz\n",
    "import pystan\n",
    "import random\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from scipy.spatial import cKDTree as KDTree\n",
    "from scipy.stats import multivariate_normal, gaussian_kde, entropy\n",
    "from fastkde import fastKDE\n",
    "from entropy_estimators import continuous\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KLdivergence(x, y):\n",
    "  # Check the dimensions are consistent\n",
    "  x = np.atleast_2d(x)\n",
    "  y = np.atleast_2d(y)\n",
    "\n",
    "  n,d = x.shape\n",
    "  m,dy = y.shape\n",
    "\n",
    "  assert(d == dy)\n",
    "\n",
    "  # Build a KD tree representation of the samples and find the nearest neighbour\n",
    "  # of each point in x.\n",
    "  xtree = KDTree(x)\n",
    "  ytree = KDTree(y)\n",
    "\n",
    "  # Get the first two nearest neighbours for x, since the closest one is the\n",
    "  # sample itself.\n",
    "  r = xtree.query(x, k=2, eps=.01, p=2)[0][:,1] + 1e-100\n",
    "  s = ytree.query(x, k=1, eps=.01, p=2)[0] + 1e-100\n",
    "\n",
    "  # There is a mistake in the paper. In Eq. 14, the right side misses a negative sign\n",
    "  # on the first term of the right hand side.\n",
    "  return -np.log(r/s).sum() * d / n + np.log(m / (n - 1.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whether to recompile the stan program\n",
    "DO_COMPILE = False\n",
    "\n",
    "# stan program path\n",
    "stan_path = 'multi_feature.stan'\n",
    "\n",
    "def build_model(path, pkl_file=None, do_compile=True):\n",
    "    if do_compile:\n",
    "        sm = pystan.StanModel(file=path)\n",
    "        if pkl_file is not None:\n",
    "            with open(pkl_file, 'wb') as f:\n",
    "                pickle.dump(sm, f)\n",
    "\n",
    "    # if the program hasn't been complied, check that the file already exists\n",
    "    else: \n",
    "        if os.path.isfile(pkl_file):\n",
    "            sm = pickle.load(open(pkl_file, 'rb'))\n",
    "        else:\n",
    "            raise FileNotFoundError\n",
    "    return sm\n",
    "\n",
    "\n",
    "sm = build_model(path = stan_path, pkl_file='model.pkl', do_compile=DO_COMPILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mu\n",
    "mu_mean = 0\n",
    "mu_sd = 0.5\n",
    "\n",
    "# sd\n",
    "sigma_alpha = 1\n",
    "sigma_beta = 1\n",
    "\n",
    "# noise SD prior\n",
    "noise = 0.25\n",
    "\n",
    "# environmental EIG\n",
    "env_info = 0.401"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# number of stimuli\n",
    "sequence_length = 6\n",
    "\n",
    "# number of features \n",
    "num_features = 1\n",
    "\n",
    "# number of samples (max)\n",
    "num_samples = 600\n",
    "\n",
    "# allocation of samples to exemplars\n",
    "exemplar_idx = np.repeat(np.arange(1, sequence_length+1), num_samples/sequence_length)\n",
    "\n",
    "# background / deviant mean values\n",
    "background = np.repeat(0, num_features)\n",
    "deviant = np.repeat(3, num_features)\n",
    "\n",
    "# perceptual noise\n",
    "sig = np.identity(num_features) * 0.01;\n",
    "\n",
    "# deviant position\n",
    "deviant_pos = 2\n",
    "\n",
    "# stimulus means\n",
    "exemplar_means = np.tile(background, (sequence_length, 1))\n",
    "exemplar_means[deviant_pos-1] = deviant\n",
    "\n",
    "sim_data = [np.random.multivariate_normal(exemplar_means[idx-1], sig) for idx in exemplar_idx] \n",
    "sim_data = np.asmatrix(sim_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of iterations and warmup per model run\n",
    "num_iter = 10000\n",
    "num_warmup = 3000\n",
    "\n",
    "# number of total model runs\n",
    "num_model_runs = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize flags, variables, iterators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flags \n",
    "sample = True\n",
    "policy = 'kl' # 'kl', 'surprisal', 'entropy' or 'eig'\n",
    "\n",
    "# Iterators\n",
    "samples_from_current_stim = 1\n",
    "total_samples = 1\n",
    "exemplar_num = 1\n",
    "\n",
    "# Variables\n",
    "model_LT = np.zeros((1, sequence_length))\n",
    "\n",
    "sample_data = np.empty((num_samples,num_features))\n",
    "sample_data[:] = np.nan\n",
    "\n",
    "exemplar_labels = np.empty((num_samples,))\n",
    "exemplar_labels[:] = np.nan\n",
    "\n",
    "prior_mu = np.random.multivariate_normal(np.repeat(mu_mean, num_features), np.identity(num_features)*mu_sd, num_iter-num_warmup)\n",
    "\n",
    "prior_sigma = np.empty((num_iter-num_warmup, num_features))\n",
    "for i in np.arange(0, num_features):\n",
    "    prior_sigma[:,i] = np.random.gamma(sigma_alpha, sigma_beta, num_iter-num_warmup)\n",
    "\n",
    "prior = np.hstack((prior_mu, prior_sigma))\n",
    "\n",
    "data = {\"mu_mean\": mu_mean , \"mu_sd\": mu_sd, \"sigma_alpha\": sigma_alpha, \"sigma_beta\": sigma_beta, \"noise\": noise, \"F\": num_features}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Action loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:295 of 7000 iterations ended with a divergence (4.21 %).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.8 to remove the divergences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient evaluation took 1.7e-05 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "Iteration:    1 / 10000 [  0%]  (Warmup)\n",
      "Iteration: 1000 / 10000 [ 10%]  (Warmup)\n",
      "Iteration: 2000 / 10000 [ 20%]  (Warmup)\n",
      "Iteration: 3000 / 10000 [ 30%]  (Warmup)\n",
      "Iteration: 3001 / 10000 [ 30%]  (Sampling)\n",
      "Iteration: 4000 / 10000 [ 40%]  (Sampling)\n",
      "Iteration: 5000 / 10000 [ 50%]  (Sampling)\n",
      "Iteration: 6000 / 10000 [ 60%]  (Sampling)\n",
      "Iteration: 7000 / 10000 [ 70%]  (Sampling)\n",
      "Iteration: 8000 / 10000 [ 80%]  (Sampling)\n",
      "Iteration: 9000 / 10000 [ 90%]  (Sampling)\n",
      "Iteration: 10000 / 10000 [100%]  (Sampling)\n",
      "\n",
      " Elapsed Time: 0.059573 seconds (Warm-up)\n",
      "               0.169982 seconds (Sampling)\n",
      "               0.229555 seconds (Total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "while sample and samples_from_current_stim > 1:\n",
    "    \n",
    "    # sample number\n",
    "    data[\"M\"] = total_samples\n",
    "\n",
    "    # exemplar number \n",
    "    data[\"K\"] = exemplar_num\n",
    "\n",
    "    # add sim data\n",
    "    sample_data[total_samples-1] = sim_data[exemplar_idx == exemplar_num][samples_from_current_stim-1]\n",
    "    data[\"z\"] = np.transpose(sample_data[0:total_samples,:])\n",
    "\n",
    "    # add exemplar for each id\n",
    "    exemplar_labels[total_samples-1] = int(exemplar_num)\n",
    "    data[\"exemplar_idx\"] = [int(x) for x in exemplar_labels[~np.isnan(exemplar_labels)]]\n",
    "\n",
    "    # get posterior samples\n",
    "    fit = sm.sampling(data=data, iter=num_iter, chains=1, warmup = num_warmup)\n",
    "\n",
    "    posterior = np.hstack((fit['mu'], fit['sigma']))\n",
    "    \n",
    "    if policy is 'kl':\n",
    "        # KL divergence between prior and posterior\n",
    "        stim_info = KLdivergence(posterior, prior)\n",
    "\n",
    "    elif policy is 'entropy':\n",
    "        # reduction of entropy\n",
    "        stim_info = entropy(prior) - entropy(posterior)\n",
    "\n",
    "    elif policy is 'surprisal':\n",
    "        # surprisal of current observation given prior\n",
    "        stim_info = surprisal(prior, sample_data[0:total_samples,:])\n",
    "\n",
    "    elif policy is 'EIG':\n",
    "        stim_info = EIG(posterior)\n",
    "    # generate hypothetical next obs\n",
    "\n",
    "\n",
    "    # get posterior predictive for each next obs\n",
    "    # post_preds = 1\n",
    "\n",
    "    # compute KL for each hypothetical next obs\n",
    "        # compute_KL(post, pre)\n",
    "\n",
    "\n",
    "    # get EIG\n",
    "    # EIG_stim = KLs * post_preds\n",
    "\n",
    "    # decision rule\n",
    "    if stim_info < env_info:\n",
    "        sample = False\n",
    "        model_LT[exemplar_num-1] = samples_from_current_stim\n",
    "\n",
    "        # reset/increment counters\n",
    "        samples_from_current_stim = 1\n",
    "        exemplar_num =+ 1\n",
    "    else:\n",
    "        samples_from_current_stim =+ 1 \n",
    "\n",
    "    if policy is 'kl' or policy is 'surprisal' or policy is 'entropy':\n",
    "        prior = posterior\n",
    "    \n",
    "    total_samples =+1\n",
    "\n",
    "\n",
    "model_LT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('stan_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "27c5f53aa2a72cb83d695644322e5c228d48779d014791c7ecd15aee1ee6a87e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
