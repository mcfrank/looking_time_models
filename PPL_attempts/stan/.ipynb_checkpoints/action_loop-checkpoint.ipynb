{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import arviz\n",
    "import pystan\n",
    "import random\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from scipy.spatial import cKDTree as KDTree\n",
    "from scipy.stats import multivariate_normal, gaussian_kde, entropy\n",
    "from fastkde import fastKDE\n",
    "from entropy_estimators import continuous\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KLdivergence(x, y):\n",
    "    # Check the dimensions are consistent\n",
    "    x = np.atleast_2d(x)\n",
    "    y = np.atleast_2d(y)\n",
    "\n",
    "    n,d = x.shape\n",
    "    m,dy = y.shape\n",
    "\n",
    "    assert(d == dy)\n",
    "\n",
    "    # Build a KD tree representation of the samples and find the nearest neighbour\n",
    "    # of each point in x.\n",
    "    xtree = KDTree(x)\n",
    "    ytree = KDTree(y)\n",
    "\n",
    "  # Get the first two nearest neighbours for x, since the closest one is the\n",
    "  # sample itself.\n",
    "    thresh = 1e-4\n",
    "    r = xtree.query(x, k=1000, eps=.01, p=2)[0]\n",
    "    r = r[np.arange(r.shape[0]), np.argmax(r > thresh, axis=1)] \n",
    "    s = ytree.query(x, k=1000, eps=.01, p=2)[0]\n",
    "    s = s[np.arange(s.shape[0]), np.argmax(s > thresh, axis=1)]\n",
    "    \n",
    "    if math.isinf(-np.log(r/s).sum() * d / n + np.log(m / (n - 1.))):\n",
    "        break\n",
    "        a = 0;\n",
    "\n",
    "\n",
    "    # There is a mistake in the paper. In Eq. 14, the right side misses a negative sign\n",
    "    # on the first term of the right hand side.\n",
    "    return -np.log(r/s).sum() * d / n + np.log(m / (n - 1.))\n",
    "\n",
    "def surprisal(dist, sample):\n",
    "    kde = gaussian_kde(dist)\n",
    "    prob = kde.evaluate(sample)\n",
    "    return -np.log(prob)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whether to recompile the stan program\n",
    "DO_COMPILE = False\n",
    "\n",
    "# simple noise or prior on noise\n",
    "SIMPLE_NOISE = True\n",
    "\n",
    "# stan program path\n",
    "if SIMPLE_NOISE:\n",
    "    stan_path = 'multi_feature_simple_noise.stan'\n",
    "    pkl_file = 'model_simple_noise.pkl'\n",
    "else:\n",
    "    stan_path = 'multi_feature.stan'\n",
    "    pkl_file = 'model.pkl'\n",
    "\n",
    "\n",
    "def build_model(path, pkl_file=None, do_compile=True):\n",
    "    if do_compile:\n",
    "        sm = pystan.StanModel(file=path)\n",
    "        if pkl_file is not None:\n",
    "            with open(pkl_file, 'wb') as f:\n",
    "                pickle.dump(sm, f)\n",
    "\n",
    "    # if the program hasn't been complied, check that the file already exists\n",
    "    else: \n",
    "        if os.path.isfile(pkl_file):\n",
    "            sm = pickle.load(open(pkl_file, 'rb'))\n",
    "        else:\n",
    "            raise FileNotFoundError\n",
    "    return sm\n",
    "\n",
    "\n",
    "sm = build_model(path = stan_path, pkl_file='model_simple_noise.pkl', do_compile=DO_COMPILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mu\n",
    "mu_mean = 0\n",
    "mu_sd = 1\n",
    "\n",
    "# sd\n",
    "sigma_alpha = 1\n",
    "sigma_beta = 1\n",
    "\n",
    "# noise SD prior\n",
    "epsilon_alpha = 1\n",
    "epsilon_beta = 1\n",
    "\n",
    "# for simple noise \n",
    "noise = 0.5\n",
    "\n",
    "# environmental EIG\n",
    "env_info = 0.002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# number of stimuli\n",
    "sequence_length = 6\n",
    "\n",
    "# number of features \n",
    "num_features = 1\n",
    "\n",
    "# number of samples (max)\n",
    "num_samples = 3000\n",
    "\n",
    "# allocation of samples to exemplars\n",
    "exemplar_idx = np.repeat(np.arange(1, sequence_length+1), num_samples/sequence_length)\n",
    "\n",
    "# background / deviant mean values\n",
    "background = np.repeat(1, num_features)\n",
    "deviant = np.repeat(3, num_features)\n",
    "\n",
    "# perceptual noise\n",
    "sig = np.identity(num_features) * 0.001;\n",
    "\n",
    "# deviant position\n",
    "deviant_pos = 6\n",
    "\n",
    "# stimulus means\n",
    "exemplar_means = np.tile(background, (sequence_length, 1))\n",
    "exemplar_means[deviant_pos-1] = deviant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of iterations and warmup per model run\n",
    "num_iter = 10000\n",
    "num_warmup = 5000\n",
    "\n",
    "# number of total model runs\n",
    "num_model_runs = 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize flags, variables, iterators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flags \n",
    "sample = True\n",
    "policy = 'kl' # 'kl', 'surprisal', 'entropy' or 'eig'\n",
    "\n",
    "# Variables\n",
    "model_LT = np.zeros((num_model_runs, sequence_length))\n",
    "\n",
    "# prior parameters\n",
    "prior_mu = np.random.multivariate_normal(np.repeat(mu_mean, num_features), np.identity(num_features)*mu_sd, num_iter-num_warmup)\n",
    "\n",
    "prior_sigma = np.empty((num_iter-num_warmup, num_features))\n",
    "for i in np.arange(0, num_features):\n",
    "    prior_sigma[:,i] = np.random.gamma(sigma_alpha, sigma_beta, num_iter-num_warmup)\n",
    "\n",
    "prior_z_rep = np.empty((num_iter-num_warmup, num_features))\n",
    "for i in np.arange(0, num_iter-num_warmup):\n",
    "    prior_z_rep[i,:] = np.random.multivariate_normal(prior_mu[i,:], np.identity(num_features)*prior_sigma[i,:])\n",
    "\n",
    "prior = np.hstack((prior_mu, prior_sigma))\n",
    "\n",
    "data = {\"mu_mean\": mu_mean , \"mu_sd\": mu_sd, \"sigma_alpha\": sigma_alpha, \"sigma_beta\": sigma_beta, \n",
    "\"epsilon_alpha\": epsilon_alpha, \"epsilon_beta\": epsilon_beta, \"noise\": noise, \"F\": num_features}\n",
    "\n",
    "stim_info = np.empty((num_model_runs, num_samples))\n",
    "stim_info[:] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Action loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ll/vmwcshdn1xd84d7z8myb9w7m0000gp/T/ipykernel_28374/2704564680.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mrun\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_model_runs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# generate the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msim_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultivariate_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexemplar_means\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexemplar_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msim_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "for run in np.arange(0, num_model_runs):\n",
    "\n",
    "    # generate the data\n",
    "    sim_data = [np.random.multivariate_normal(exemplar_means[idx-1], sig) for idx in exemplar_idx] \n",
    "    sim_data = np.asmatrix(sim_data)\n",
    "\n",
    "    # Iterators\n",
    "    samples_from_current_stim = 1\n",
    "    total_samples = 1\n",
    "    exemplar_num = 1\n",
    "\n",
    "    # initialize data\n",
    "    sample_data = np.empty((num_samples,num_features))\n",
    "    sample_data[:] = np.nan\n",
    "\n",
    "    exemplar_labels = np.empty((num_samples,))\n",
    "    exemplar_labels[:] = np.nan\n",
    "\n",
    "    while sample or samples_from_current_stim > 1:\n",
    "        \n",
    "        # sample number\n",
    "        data[\"M\"] = total_samples\n",
    "\n",
    "        # exemplar number \n",
    "        data[\"K\"] = exemplar_num\n",
    "\n",
    "        # add sim data\n",
    "        sample_data[total_samples-1] = sim_data[exemplar_idx == exemplar_num][samples_from_current_stim-1]\n",
    "        data[\"z\"] = np.transpose(sample_data[0:total_samples,:])\n",
    "\n",
    "        # add exemplar for each id\n",
    "        exemplar_labels[total_samples-1] = int(exemplar_num)\n",
    "        data[\"exemplar_idx\"] = [int(x) for x in exemplar_labels[~np.isnan(exemplar_labels)]]\n",
    "\n",
    "        # get posterior samples\n",
    "        fit = sm.sampling(data=data, iter=num_iter, chains=4, warmup = num_warmup,control=dict(adapt_delta=0.95));\n",
    "\n",
    "        posterior = np.hstack((fit['mu'], fit['sigma']))\n",
    "        \n",
    "        if policy is 'kl':\n",
    "\n",
    "            if total_samples > 20:\n",
    "                a = 0;\n",
    "\n",
    "            # KL divergence between prior and posterior\n",
    "            stim_info[run, total_samples-1] = KLdivergence(posterior, prior)\n",
    "\n",
    "        elif policy is 'entropy':\n",
    "            # reduction of entropy\n",
    "            stim_info[run,total_samples-1] = entropy(prior) - entropy(posterior)\n",
    "\n",
    "        elif policy is 'surprisal':\n",
    "\n",
    "            # surprisal of current observation given prior\n",
    "            stim_info[run, total_samples-1] = surprisal(prior[:,2], sample_data[total_samples-1])\n",
    "\n",
    "        elif policy is 'EIG':\n",
    "            stim_info[run,total_samples-1] = EIG(posterior)\n",
    "\n",
    "        # decision rule\n",
    "        if stim_info[run,total_samples-1] < env_info:\n",
    "            model_LT[run, exemplar_num-1] = samples_from_current_stim\n",
    "\n",
    "            # reset/increment counters\n",
    "            samples_from_current_stim = 1\n",
    "            exemplar_num += 1\n",
    "\n",
    "            if exemplar_num > sequence_length:\n",
    "                sample = False\n",
    "\n",
    "        else:\n",
    "            samples_from_current_stim += 1 \n",
    "\n",
    "        if policy is 'kl' or policy is 'surprisal' or policy is 'entropy':\n",
    "            prior = posterior\n",
    "        \n",
    "        total_samples += 1\n",
    "\n",
    "    # start sampling for next model run\n",
    "    sample = True\n",
    "\n",
    "\n",
    "plt.plot(np.arange(1,sequence_length+1), np.mean(model_LT, axis = 0).squeeze(), 'k*')\n",
    "\n",
    "plt.xlabel(\"stim index\")\n",
    "plt.ylabel(\"model samples\")\n",
    "plt.title(\"\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(np.arange(1,total_samples+1),np.mean(stim_info, axis = 0)[0:total_samples].squeeze())\n",
    "\n",
    "plt.xlabel(\"sample index\")\n",
    "plt.ylabel(\"KL\")\n",
    "plt.title(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.92009985,         inf,         inf, ...,         nan,\n",
       "                nan,         nan],\n",
       "       [ 3.09337532, -0.03814948,  0.21258669, ...,         nan,\n",
       "                nan,         nan],\n",
       "       [ 2.9603826 , -0.13657292,  0.50851506, ...,         nan,\n",
       "                nan,         nan]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stim_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.,  4.,  8.,  2., 14.,  4.],\n",
       "       [ 3.,  6.,  3., 11.,  6.,  4.],\n",
       "       [ 3.,  3.,  9.,  5.,  3.,  5.]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "27c5f53aa2a72cb83d695644322e5c228d48779d014791c7ecd15aee1ee6a87e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
