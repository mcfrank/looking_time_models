---
title: "R Notebook"
output: html_notebook
---



```{r}
library(tidyverse)
library(here)
library(matrixStats)
library(profvis)

source(here("helper/get_stimuli.R"))
source(here("helper/get_observation.R"))
source(here("helper/grid_approximation.R"))
source(here("helper/noisy_update.R"))

source(here("helper/get_kl_eig.R"))

```

```{r}
num_features = 3
num_features_simple = 1
trials_per_block = 8
deviant_positions = 4
dissimilarity_ratio = 0.2
epsilon = 0.1

## grid approximation related 
grid_theta <- seq(0.1, 1, 0.2)
grid_epsilon <- seq(0.1, 1, 0.2)
alpha_prior = 1
beta_prior = 1
alpha_epsilon = 10 
beta_epsilon = 1

## eig related 
env_eig = 0.005
max_obs = 500

## experiment related 
subject_n = 10
```

```{r}
simple_stimuli <- generate_creature_sequence(
  block_length = trials_per_block, 
  deviant_positions = deviant_positions,  # takes a vector, 
  total_feature = num_features, 
  feature_theta = 0.8, 
  feature_number = num_features_simple, 
  dissimilar_ratio = dissimilarity_ratio)
```

```{r}
profvis({
  simple_stimuli <- generate_creature_sequence(
  block_length = trials_per_block, 
  deviant_positions = deviant_positions,  # takes a vector, 
  total_feature = num_features, 
  feature_theta = 0.8, 
  feature_number = num_features_simple, 
  dissimilar_ratio = dissimilarity_ratio)
  
})
```



```{r}
main_simulation <- function(
                          subject, 
                          stimuli_sequence, 
                          noise_parameter, 
                          eig_from_world = .005,
                          max_observation = 500, # should this be per trial or in total? currently in total 
                          grid_theta = grid_theta, 
                          grid_epsilon = grid_epsilon, 
                          alpha_prior = alpha_prior, 
                          beta_prior = beta_prior,
                          alpha_epsilon = alpha_epsilon, 
                          beta_epsilon = beta_epsilon
                          ){
  
  # set up the df that tracks eig  
  df <- tibble(t = rep(NA,max_observation),
             stimulus_idx = rep(NA,max_observation), 
             EIG = rep(NA,max_observation), 
             p_look_away = rep(NA,max_observation), 
             look_away = rep(NA,max_observation))

  
  # set up the df that keep trakc of observation 
  observations <-  stimuli_sequence %>% 
    # create an empty dataframe with all the info needed to be tracked 
    filter(is.na(.)) %>% 
    mutate(t = NA_integer_) 
  
  
  # the total number of stimuli 
  total_trial_number = nrow(stimuli_sequence)
  total_feature_number = stimuli_sequence %>% 
    select(starts_with("V")) %>% 
    ncol()
  


  # which stimulus are we looking at
    stimulus_idx <- 1
    t <- 1
  
  
  while(stimulus_idx <= total_trial_number){
    
    current_stimulus <- stimuli_sequence %>% 
      filter(trial_number == stimulus_idx)
    
    current_observation <- noisy_observation_creature(
                                stimuli_df = stimuli_sequence,
                                trial_index  = stimulus_idx, 
                                n_sample = 1, 
                                epsilon = noise_parameter
                              )
    
    # add to current observation 
    observations <- bind_rows(observations, 
                              current_observation %>% mutate(
                                trial_number = stimulus_idx, 
                                trial_type = current_stimulus$trial_type,
                                t = t))
    
    # calculate posterior at t 
    # optimization possible!
    posterior_at_t <- grid_apprxoimation_with_observation(
                          noisy_observation = observations, 
                          track_epsilon = TRUE, 
                          grid_theta = grid_theta, 
                          grid_epsilon = grid_epsilon, 
                          alpha_prior = alpha_prior, 
                          beta_prior = beta_prior,
                          alpha_epsilon = alpha_epsilon, 
                          beta_epsilon = beta_epsilon
                        )
    

    
    # maybe needs scaling?
    
    df$t[t] = t
    df$stimulus_idx[t] = stimulus_idx
    
    df$EIG[t] = get_eig(current_observation, 
                    observations, 
                    posterior_at_t, 
                    grid_theta = grid_theta, 
                    grid_epsilon = grid_epsilon, 
                    alpha_prior = alpha_prior, 
                    beta_prior = beta_prior,
                    alpha_epsilon = alpha_epsilon, 
                    beta_epsilon = beta_epsilon)
    
    # flip a coin with p_keep_looking weight
    df$p_look_away[t] = eig_from_world / (df$EIG[t] + eig_from_world)
    df$look_away[t] = rbinom(1, 1, prob = df$p_look_away[t]) == 1

    if (df$look_away[t]==TRUE) {
      stimulus_idx <- stimulus_idx + 1
    }
    
    t <- t + 1 
      
      
  }
    
  df <- df %>% mutate(id = subject)
  
  
  return(df)
}


profvis(
sims <- lapply(seq(1, 1, 1), 
         function(x){
           main_simulation(subject = x,
                          stimuli_sequence = simple_stimuli, 
                          noise_parameter = epsilon, 
                          eig_from_world = env_eig,
                          max_observation = max_obs, # should this be per trial or in total? currently per trial 
                          grid_theta = grid_theta, 
                          grid_epsilon = grid_epsilon, 
                          alpha_prior = alpha_prior, 
                          beta_prior = beta_prior,
                          alpha_epsilon = alpha_epsilon, 
                          beta_epsilon = beta_epsilon)
         }
  ) %>% 
    bind_rows()

)
```


# Most expensive function 

```{r}
noisy_observation = noisy_observation_creature(
                                stimuli_df = simple_stimuli,
                                trial_index  = 1, 
                                n_sample = 1, 
                                epsilon = noise_parameter
                              )


profvis(
posterior_df <- lapply(seq(1, num_features, 1), 
         function(x){
           update_grid_with_theta_and_epsilon(
             feature_i = x, 
             grid_theta = grid_theta, 
             grid_epsilon = grid_epsilon, 
             observations = noisy_observation[,x], 
             alpha_theta = alpha_prior, 
             beta_theta = beta_prior,
             alpha_epsilon = alpha_epsilon, 
             beta_epsilon = beta_epsilon
           )
         })
)
```

ok try to treat ya 
```{r}
update_grid_with_theta_and_epsilon_better <- function(
  feature_i, 
  grid_theta, 
  grid_epsilon, 
  observations, 
  alpha_theta, beta_theta, 
  alpha_epsilon, beta_epsilon
){
  
  
  samps <- expand_grid(theta = grid_theta,
                       epsilon = grid_epsilon) 
  
  
  samps$unnormalized_log_posterior <- mapply(function(x, y) 
    lp_theta_given_z(z_bar = observations, 
                     theta = x, 
                     epsilon = y, 
                     alpha_theta = alpha_theta, 
                     beta_theta = beta_theta,
                     alpha_epsilon = alpha_epsilon, 
                     beta_epsilon = beta_epsilon), 
    samps$theta, 
    samps$epsilon)
  
  samps$log_posterior = samps$unnormalized_log_posterior - matrixStats::logSumExp(samps$unnormalized_log_posterior)
  
  # integrate out epsilon by summing p(theta | z) over all the different possible values of epsilon
  # that's the log-sum-exp line
  theta_posterior <- samps %>%
    group_by(theta) %>%
    summarise(log_posterior = matrixStats::logSumExp(log_posterior)) %>%
    mutate(posterior = exp(log_posterior)) %>% 
    mutate(feature_index = feature_i)
  
  return(theta_posterior)
  
}
```

so it turns out you are a huge problem, let's test you for a bit 



```{r}

observations = noisy_observation[,1]

lp_theta_given_z <- function(z_bar, 
                             theta, epsilon, 
                             alpha_theta, beta_theta, 
                             alpha_epsilon, beta_epsilon) {
 
  lp_z_given_theta(z_bar, theta, epsilon) + 
    lp_theta(theta, alpha_theta, beta_theta) + 
    lp_epsilon(epsilon, alpha_epsilon, beta_epsilon)
}


lp_z_given_theta_better <- function(z_bar, 
                             theta, 
                             epsilon){
  
  z_bar = z_bar %>% pull()
  sum(sapply(z_bar, 
             function(x){lp_z_ij_given_theta(zij = x, 
                                                    theta = theta, 
                                                    epsilon = epsilon)}))
  
  
}
```


so i think the issue is the sequential updating rule is kinda annoying, what if we do it in the more reasonable way? let's first test if we can actually have the equivalent results 

```{r}
observations <-  stimuli_sequence %>% 
    # create an empty dataframe with all the info needed to be tracked 
    filter(is.na(.)) %>% 
    mutate(t = NA_integer_) 


o1 <- noisy_observation_creature(
                                stimuli_df = stimuli_sequence,
                                trial_index  = 1, 
                                n_sample = 1, 
                                epsilon = noise_parameter
                              )
    
    # add to current observation 
o1 <- bind_rows(observations, 
                              o1 %>% mutate(
                                trial_number = stimulus_idx, 
                                trial_type = current_stimulus$trial_type,
                                t = 1))

o2 <- noisy_observation_creature(
                                stimuli_df = stimuli_sequence,
                                trial_index  = 1, 
                                n_sample = 1, 
                                epsilon = noise_parameter
                              )

os <- bind_rows(o1, 
                              o2 %>% mutate(
                                trial_number = stimulus_idx, 
                                trial_type = current_stimulus$trial_type,
                                t = 2))
    
    # calculate posterior at t 
    # optimization possible!
  posterior_after_os <- grid_apprxoimation_with_observation(
                          noisy_observation = os, 
                          track_epsilon = TRUE, 
                          grid_theta = grid_theta, 
                          grid_epsilon = grid_epsilon, 
                          alpha_prior = alpha_prior, 
                          beta_prior = beta_prior,
                          alpha_epsilon = alpha_epsilon, 
                          beta_epsilon = beta_epsilon
                        )
  
   posterior_after_o1 <- grid_apprxoimation_with_observation(
                          noisy_observation = o1, 
                          track_epsilon = TRUE, 
                          grid_theta = grid_theta, 
                          grid_epsilon = grid_epsilon, 
                          alpha_prior = alpha_prior, 
                          beta_prior = beta_prior,
                          alpha_epsilon = alpha_epsilon, 
                          beta_epsilon = beta_epsilon
                        )
  
   posterior_after_os
   posterior_after_o1
```


now let's see if we can get sth equivaleent of os using the more efficient way of calculation 
```{r}
source(here("helper/faster_noisy_update.R"))

faster_grid_apprxoimation_with_observation(
  noisy_observation = os, # i doubt this is a good idea
  last_update_posterior_df = posterior_after_o1, 
  track_epsilon = TRUE, 
  grid_theta = grid_theta, 
                          grid_epsilon = grid_epsilon, 
                          alpha_prior = alpha_prior, 
                          beta_prior = beta_prior,
                          alpha_epsilon = alpha_epsilon, 
                          beta_epsilon = beta_epsilon
  
)

```

yeah equivalent! maybe we should time them now! let's make them relatively expensive 

```{r}
expensive_theta <- seq(0.01, .99, .01)
expsensive_epsilon <- seq(0.01, .99, .01)
```


## the old way 
```{r}
ptm <- proc.time()

 posterior_after_os <- grid_apprxoimation_with_observation(
                          noisy_observation = os, 
                          track_epsilon = TRUE, 
                          grid_theta = expensive_theta, 
                          grid_epsilon = expsensive_epsilon, 
                          alpha_prior = alpha_prior, 
                          beta_prior = beta_prior,
                          alpha_epsilon = alpha_epsilon, 
                          beta_epsilon = beta_epsilon
                        )
 
 proc.time() - ptm

```

## the new way 
```{r}
ptm <- proc.time()

posterior_after_o1 <- grid_apprxoimation_with_observation(
                          noisy_observation = o1, 
                          track_epsilon = TRUE, 
                          grid_theta = expensive_theta, 
                          grid_epsilon = expsensive_epsilon, 
                          alpha_prior = alpha_prior, 
                          beta_prior = beta_prior,
                          alpha_epsilon = alpha_epsilon, 
                          beta_epsilon = beta_epsilon
                        )


faster_grid_apprxoimation_with_observation(
  noisy_observation = os, # i doubt this is a good idea
  last_update_posterior_df = posterior_after_o1, 
  track_epsilon = TRUE, 
  grid_theta = expensive_theta, 
                          grid_epsilon = expsensive_epsilon, 
                          alpha_prior = alpha_prior, 
                          beta_prior = beta_prior,
                          alpha_epsilon = alpha_epsilon, 
                          beta_epsilon = beta_epsilon
  
)

proc.time() - ptm

```

ughhhh awkward 
hypothesis: maybe it is because i'm not doing enough number of updates? maybe the benefit would show up in the long term? 

```{r}
o100 <- noisy_observation_creature(
                                stimuli_df = stimuli_sequence,
                                trial_index  = 1, 
                                n_sample = 100, 
                                epsilon = noise_parameter
                              )

o100
```

tbd 

