---
title: "R Notebook"
output: html_notebook
---


http://winvector.github.io/Accumulation/Accum.html








```{r}
library(tidyverse)
library(here)
library(matrixStats)
library(profvis)
library(microbenchmark)

source(here("helper/get_stimuli.R"))
source(here("helper/get_observation.R"))
source(here("helper/grid_approximation.R"))
source(here("helper/noisy_update.R"))
source(here("helper/main_simulation.R"))
source(here("helper/get_kl_eig.R"))

```

```{r}
num_features = 1
num_features_simple = 1
num_feature_complex = 6
trials_per_block = 3
deviant_positions = 2
feature_theta = 0.9
dissimilarity_ratio = 0.9
noise_parameter = 0.1

## grid approximation related 
grid_theta <- seq(0.1, 1, 0.2)
grid_epsilon <- seq(0.1, 1, 0.2)
alpha_theta = 1
beta_theta = 1

alpha_prior = 1
beta_prior = 1
alpha_epsilon = 10 
beta_epsilon = 1

## eig related 
env_eig = 0.005
max_obs = 500

## experiment related 
subject_n = 10
```

```{r, include=FALSE}
simple_stimuli <- generate_creature_sequence(
  block_length = trials_per_block, 
  deviant_positions = deviant_positions,  # takes a vector, 
  total_feature = num_features, 
  feature_theta = feature_theta, 
  feature_number = num_features_simple, 
  dissimilar_ratio = dissimilarity_ratio)

```




```{r}
library(microbenchmark)
library(profvis)

subject_n = 10

no_optimization <- function(){

sims <- lapply(seq(1, subject_n, 1), 
         function(x){
           main_simulation(subject = x,
                          stimuli_sequence = simple_stimuli, 
                          noise_parameter = noise_parameter, 
                          eig_from_world = env_eig,
                          max_observation = max_obs, # should this be per trial or in total? currently per trial 
                          grid_theta = grid_theta, 
                          grid_epsilon = grid_epsilon, 
                          alpha_prior = alpha_prior, 
                          beta_prior = beta_prior,
                          alpha_epsilon = alpha_epsilon, 
                          beta_epsilon = beta_epsilon, 
                          forced_exposure = TRUE,
                          forced_sample = 5,
                          optimize = FALSE)
         }
  ) %>% 
    bind_rows()
}

with_optimization <- function(){
  
  sims <- lapply(seq(1, subject_n, 1), 
         function(x){
           main_simulation(subject = x,
                          stimuli_sequence = simple_stimuli, 
                          noise_parameter = noise_parameter, 
                          eig_from_world = env_eig,
                          max_observation = max_obs, # should this be per trial or in total? currently per trial 
                          grid_theta = grid_theta, 
                          grid_epsilon = grid_epsilon, 
                          alpha_prior = alpha_prior, 
                          beta_prior = beta_prior,
                          alpha_epsilon = alpha_epsilon, 
                          beta_epsilon = beta_epsilon, 
                          forced_exposure = TRUE,
                          forced_sample = 5,
                          optimize = TRUE)
         }
  ) %>% 
    bind_rows()
  
  
}

# profvis(no_optimization())
profvis(with_optimization())
#with_optimization()

#microbenchmark(no_optimization(), 
 #              with_optimization(),times = 10)


```
```{r}
vect <- seq(1,10,1)

microbenchmark( lapply(p, function(x){z_bar}), 
                p[[1]] <- z_bar,
                times = 100000)
```

```{r}
list_df <- lapply(seq(1, 1000, 1), 
                  function(x){tibble("x" = 1)})


names(list_df) <- as.character(seq(1, 1000,1))

library(dict)
library(hash)

keys = as.character(seq(1, 1000, 1))
hash_df <- hash(list_df)
hash_df$"10"


microbenchmark(  t==1,
                times = 5000)

list_df[[10]]
```

```{r}
pre_optimization <- function(){
  
  unnormalized_log_posterior <-  mapply(function(x, y) 
    init_lp_theta_given_z(observation = observation, 
                     theta = x, 
                     epsilon = y, 
                     alpha_theta = alpha_theta, 
                     beta_theta = beta_theta,
                     alpha_epsilon = alpha_epsilon, 
                     beta_epsilon = beta_epsilon), 
    posterior_df$theta, 
    posterior_df$epsilon)
  
}

after_optimization <- function(){
  
  cheaper_unnormalized_log_posterior <-  cheaper_lp_theta_given_z(observation, 
                                                                    grid_theta, 
                                                                    grid_epsilon,
                                                                    posterior_df, 
                                                                    alpha_theta, beta_theta, 
                                                                    alpha_epsilon, beta_epsilon)

  
}

bm<- bench::mark(
  pre_optimization(), 
  after_optimization()
  
)
bm
autoplot(bm)
```
```{r}
update_grid_with_theta_and_epsilon <- function(
  feature_i, 
  grid_theta, 
  grid_epsilon, 
  observations, 
  alpha_theta, beta_theta, 
  alpha_epsilon, beta_epsilon){
  
  
  samps <- expand_grid(theta = grid_theta,
                       epsilon = grid_epsilon) 
  
  
  samps$unnormalized_log_posterior <- mapply(function(x, y) 
    lp_theta_given_z(z_bar = na.omit(observations), 
                     theta = x, 
                     epsilon = y, 
                     alpha_theta = alpha_theta, 
                     beta_theta = beta_theta,
                     alpha_epsilon = alpha_epsilon, 
                     beta_epsilon = beta_epsilon), 
    samps$theta, 
    samps$epsilon)
  
  samps$log_posterior = samps$unnormalized_log_posterior - matrixStats::logSumExp(samps$unnormalized_log_posterior)
  
  
    samps$posterior <- exp(samps$log_posterior)
    samps$feature_index <- feature_i
   
  
  
  
  
  return(samps)
  
}


grid_apprxoimation_with_observation <- function(
  noisy_observation, 
  grid_theta = seq(0.01, .99, .01), 
  grid_epsilon = seq(0.01, .99, .01), 
  alpha_prior = 1, 
  beta_prior = 1,
  alpha_epsilon = 10, 
  beta_epsilon = 1
){
  
    posterior_df <- lapply(seq(1, 
                               ncol(noisy_observation[startsWith(names(noisy_observation), 
                                                                 "V")]), 
                               1), 
                           function(x){
                             update_grid_with_theta_and_epsilon(
                               feature_i = x, 
                               grid_theta = grid_theta, 
                               grid_epsilon = grid_epsilon, 
                               observations = noisy_observation[,x], 
                               alpha_theta = alpha_prior, 
                               beta_theta = beta_prior,
                               alpha_epsilon = alpha_epsilon, 
                               beta_epsilon = beta_epsilon
                             )
                           }
    ) %>% 
      bind_rows()
    
    
  
  
  
    return (posterior_df)
  


}
```


# compare two ways of doing grid approximation 
```{r}
iteration = 500
feature_number = 1
grid_theta = seq(0.01, 0.99, 0.01)
grid_epsilon = seq(0.01, 0.99, 0.01)
obs_s <- noisy_observation_creature(
      stimuli_df = stimuli_sequence,
      trial_index  = 1, 
      n_sample = iteration, 
      epsilon = noise_parameter
    )

new_grid_approximation <- function(obs_s, iteration){
  
  df_lp_theta_epsilon <- get_df_lp_theta_epsilon(grid_theta, grid_epsilon, 
                                                 alpha_theta, beta_theta, 
                                                 alpha_epsilon, beta_epsilon)
  df_posterior <- expand_grid(theta = grid_theta,
                              epsilon = grid_epsilon,
                              feature_index = seq(1, feature_number))
  # not sure when do we really need the non-log one, save some $$$  
  df_posterior$unnormalized_log_posterior <- NA_real_
  df_posterior$log_posterior <- NA_real_


  list_df_posterior <- lapply(seq(1, iteration, 1), 
                              function(x){df_posterior})
  
  
  t = 1
  while(t <= iteration){
    
    if(t == 1){
      # do some fresh calculation
      
      list_df_posterior[[t]] <- init_update( list_df_posterior[[t]], 
                                             df_lp_theta_epsilon, 
                                             obs_s[t, ],
                                             grid_theta, grid_epsilon,
                                             alpha_theta, beta_theta, 
                                             alpha_epsilon, beta_epsilon)
    }else{
      list_df_posterior[[t]] <- cheaper_update_posterior(previous_posterior_df =  list_df_posterior[[t-1]],
                                                         current_posterior_df =  list_df_posterior[[t]], 
                                                         obs_s[t, ], 
                                                         grid_theta, grid_epsilon)
    }
    
    t = t + 1
  
  
  }
  
  new_pos <- list_df_posterior[[iteration]]

  return(new_pos$unnormalized_log_posterior)
}

old_grid_approximation <- function(obs_s, iteration){
  
  old_pos <- grid_apprxoimation_with_observation(
  obs_s, 
  grid_theta,
  grid_epsilon,  
  alpha_theta, 
  beta_theta,
  alpha_epsilon, 
  beta_epsilon)
  
  return(old_pos$unnormalized_log_posterior)
  
}



bm_grid_approx <- bench::mark(
  new_grid_approximation(obs_s, iteration), 
  old_grid_approximation(obs_s, iteration)
)

bm_grid_approx
bm_grid_approx %>% autoplot()


```


## get all permuations of creatures 
```{r}
test_observation <- rep(TRUE, 5) %>% as_tibble_row(.name_repair = "unique")

old_get_possible_creatures <- function(test_observation){
  get_possible_creatures(test_observation)

}



cheaper_get_possible_creatures <- function(feature_n){
  
  
    flip_observation <- as.logical(1 - (current_observation) %>% 
                                   as.logical()) %>% 
    as.vector() %>% 
    as_tibble_row(.name_repair = ~ names(current_observation)) 
  
  combine_observations <- bind_rows(current_observation, flip_observation)
  
  all_possible_creatures <- combine_observations %>% 
    cross_df() %>% 
    mutate(index = row_number())
  
  
  
}


```













