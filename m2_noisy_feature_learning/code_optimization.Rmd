---
title: "R Notebook"
output: html_notebook
---


http://winvector.github.io/Accumulation/Accum.html








```{r}
library(tidyverse)
library(here)
library(matrixStats)
library(profvis)
library(microbenchmark)

source(here("helper/get_stimuli.R"))
source(here("helper/get_observation.R"))
source(here("helper/grid_approximation.R"))
source(here("helper/noisy_update.R"))
source(here("helper/main_simulation.R"))
source(here("helper/get_kl_eig.R"))

```

```{r}
num_features = 1
num_features_simple = 1
num_feature_complex = 6
trials_per_block = 3
deviant_positions = 2
feature_theta = 0.9
dissimilarity_ratio = 0.9
noise_parameter = 0.1

## grid approximation related 
grid_theta <- seq(0.1, 1, 0.2)
grid_epsilon <- seq(0.1, 1, 0.2)
alpha_theta = 1
beta_theta = 1

alpha_prior = 1
beta_prior = 1
alpha_epsilon = 10 
beta_epsilon = 1

## eig related 
env_eig = 0.005
max_obs = 500

## experiment related 
subject_n = 10
```

```{r, include=FALSE}
simple_stimuli <- generate_creature_sequence(
  block_length = trials_per_block, 
  deviant_positions = deviant_positions,  # takes a vector, 
  total_feature = num_features, 
  feature_theta = feature_theta, 
  feature_number = num_features_simple, 
  dissimilar_ratio = dissimilarity_ratio)

multifeature_stimuli <- generate_creature_sequence(block_length = trials_per_block, 
  deviant_positions = deviant_positions,  # takes a vector, 
  total_feature = 10, 
  feature_theta = feature_theta, 
  feature_number = num_features_simple, 
  dissimilar_ratio = dissimilarity_ratio)
```




```{r}
library(microbenchmark)
library(profvis)

subject_n = 10

no_optimization <- function(){

sims <- lapply(seq(1, subject_n, 1), 
         function(x){
           main_simulation(subject = x,
                          stimuli_sequence = simple_stimuli, 
                          noise_parameter = noise_parameter, 
                          eig_from_world = env_eig,
                          max_observation = max_obs, # should this be per trial or in total? currently per trial 
                          grid_theta = grid_theta, 
                          grid_epsilon = grid_epsilon, 
                          alpha_prior = alpha_prior, 
                          beta_prior = beta_prior,
                          alpha_epsilon = alpha_epsilon, 
                          beta_epsilon = beta_epsilon, 
                          forced_exposure = TRUE,
                          forced_sample = 5,
                          optimize = FALSE)
         }
  ) %>% 
    bind_rows()
}

with_optimization <- function(){
  
  sims <- lapply(seq(1, subject_n, 1), 
         function(x){
           main_simulation(subject = x,
                          stimuli_sequence = simple_stimuli, 
                          noise_parameter = noise_parameter, 
                          eig_from_world = env_eig,
                          max_observation = max_obs, # should this be per trial or in total? currently per trial 
                          grid_theta = grid_theta, 
                          grid_epsilon = grid_epsilon, 
                          alpha_prior = alpha_prior, 
                          beta_prior = beta_prior,
                          alpha_epsilon = alpha_epsilon, 
                          beta_epsilon = beta_epsilon, 
                          forced_exposure = TRUE,
                          forced_sample = 5,
                          optimize = TRUE)
         }
  ) %>% 
    bind_rows()
  
  
}

# profvis(no_optimization())
profvis(with_optimization())
#with_optimization()

#microbenchmark(no_optimization(), 
 #              with_optimization(),times = 10)


```
```{r}
vect <- seq(1,10,1)

microbenchmark( lapply(p, function(x){z_bar}), 
                p[[1]] <- z_bar,
                times = 100000)
```

```{r}
list_df <- lapply(seq(1, 1000, 1), 
                  function(x){tibble("x" = 1)})


names(list_df) <- as.character(seq(1, 1000,1))

library(dict)
library(hash)

keys = as.character(seq(1, 1000, 1))
hash_df <- hash(list_df)
hash_df$"10"


microbenchmark(  t==1,
                times = 5000)

list_df[[10]]
```

```{r}
pre_optimization <- function(){
  
  unnormalized_log_posterior <-  mapply(function(x, y) 
    init_lp_theta_given_z(observation = observation, 
                     theta = x, 
                     epsilon = y, 
                     alpha_theta = alpha_theta, 
                     beta_theta = beta_theta,
                     alpha_epsilon = alpha_epsilon, 
                     beta_epsilon = beta_epsilon), 
    posterior_df$theta, 
    posterior_df$epsilon)
  
}

after_optimization <- function(){
  
  cheaper_unnormalized_log_posterior <-  cheaper_lp_theta_given_z(observation, 
                                                                    grid_theta, 
                                                                    grid_epsilon,
                                                                    posterior_df, 
                                                                    alpha_theta, beta_theta, 
                                                                    alpha_epsilon, beta_epsilon)

  
}

bm<- bench::mark(
  pre_optimization(), 
  after_optimization()
  
)
bm
autoplot(bm)
```
```{r FUNCTION}
update_grid_with_theta_and_epsilon <- function(
  feature_i, 
  grid_theta, 
  grid_epsilon, 
  observations, 
  alpha_theta, beta_theta, 
  alpha_epsilon, beta_epsilon){
  
  
  samps <- expand_grid(theta = grid_theta,
                       epsilon = grid_epsilon) 
  
  
  samps$unnormalized_log_posterior <- mapply(function(x, y) 
    lp_theta_given_z(z_bar = na.omit(observations), 
                     theta = x, 
                     epsilon = y, 
                     alpha_theta = alpha_theta, 
                     beta_theta = beta_theta,
                     alpha_epsilon = alpha_epsilon, 
                     beta_epsilon = beta_epsilon), 
    samps$theta, 
    samps$epsilon)
  
  samps$log_posterior = samps$unnormalized_log_posterior - matrixStats::logSumExp(samps$unnormalized_log_posterior)
  
  
    samps$posterior <- exp(samps$log_posterior)
    samps$feature_index <- feature_i
   
  
  
  
  
  return(samps)
  
}


grid_apprxoimation_with_observation <- function(
  noisy_observation, 
  grid_theta = seq(0.01, .99, .01), 
  grid_epsilon = seq(0.01, .99, .01), 
  alpha_prior = 1, 
  beta_prior = 1,
  alpha_epsilon = 10, 
  beta_epsilon = 1
){
  
    posterior_df <- lapply(seq(1, 
                               ncol(noisy_observation[startsWith(names(noisy_observation), 
                                                                 "V")]), 
                               1), 
                           function(x){
                             update_grid_with_theta_and_epsilon(
                               feature_i = x, 
                               grid_theta = grid_theta, 
                               grid_epsilon = grid_epsilon, 
                               observations = noisy_observation[,x], 
                               alpha_theta = alpha_prior, 
                               beta_theta = beta_prior,
                               alpha_epsilon = alpha_epsilon, 
                               beta_epsilon = beta_epsilon
                             )
                           }
    ) %>% 
      bind_rows()
    
    
  
  
  
    return (posterior_df)
  


}
```


# compare two ways of doing grid approximation 
```{r}
iteration = 500
feature_number = 1
grid_theta = seq(0.01, 0.99, 0.01)
grid_epsilon = seq(0.01, 0.99, 0.01)
obs_s <- noisy_observation_creature(
      stimuli_df = stimuli_sequence,
      trial_index  = 1, 
      n_sample = iteration, 
      epsilon = noise_parameter
    )

new_grid_approximation <- function(obs_s, iteration){
  
  df_lp_theta_epsilon <- get_df_lp_theta_epsilon(grid_theta, grid_epsilon, 
                                                 alpha_theta, beta_theta, 
                                                 alpha_epsilon, beta_epsilon)
  df_posterior <- expand_grid(theta = grid_theta,
                              epsilon = grid_epsilon,
                              feature_index = seq(1, feature_number))
  # not sure when do we really need the non-log one, save some $$$  
  df_posterior$unnormalized_log_posterior <- NA_real_
  df_posterior$log_posterior <- NA_real_


  list_df_posterior <- lapply(seq(1, iteration, 1), 
                              function(x){df_posterior})
  
  
  t = 1
  while(t <= iteration){
    
    if(t == 1){
      # do some fresh calculation
      
      list_df_posterior[[t]] <- init_update( list_df_posterior[[t]], 
                                             df_lp_theta_epsilon, 
                                             obs_s[t, ],
                                             grid_theta, grid_epsilon,
                                             alpha_theta, beta_theta, 
                                             alpha_epsilon, beta_epsilon)
    }else{
      list_df_posterior[[t]] <- cheaper_update_posterior(previous_posterior_df =  list_df_posterior[[t-1]],
                                                         current_posterior_df =  list_df_posterior[[t]], 
                                                         obs_s[t, ], 
                                                         grid_theta, grid_epsilon)
    }
    
    t = t + 1
  
  
  }
  
  new_pos <- list_df_posterior[[iteration]]

  return(new_pos$unnormalized_log_posterior)
}

old_grid_approximation <- function(obs_s, iteration){
  
  old_pos <- grid_apprxoimation_with_observation(
  obs_s, 
  grid_theta,
  grid_epsilon,  
  alpha_theta, 
  beta_theta,
  alpha_epsilon, 
  beta_epsilon)
  
  return(old_pos$unnormalized_log_posterior)
  
}



bm_grid_approx <- bench::mark(
  new_grid_approximation(obs_s, iteration), 
  old_grid_approximation(obs_s, iteration)
)

bm_grid_approx
bm_grid_approx %>% autoplot()


```


## get all permuations of creatures 
```{r}
multifeature_observation <- multifeature_stimuli[1, ][startsWith(names(multifeature_stimuli), 
                                                           "V")]

posterior_at_t <- grid_apprxoimation_with_observation(
  multifeature_observation, 
  grid_theta,
  grid_epsilon,  
  alpha_theta, 
  beta_theta,
  alpha_epsilon, 
  beta_epsilon)   

all_possible_creatures <- get_possible_creatures(multifeature_observation)

```

```{r}
all_possible_creatures %>% 
  mutate(
    num_true = V1 + V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10
  ) %>% 
  group_by(num_true) %>% 
  ggplot(aes(x = num_true)) + 
  geom_histogram()
#%>% 
  #summarise(num = count(num_true))
```


```{r}
kls <- get_possible_kls(
  multifeature_observation, 
  all_possible_creatures, 
  posterior_at_t, 
  grid_theta = grid_theta, 
  grid_epsilon = grid_epsilon, 
  alpha_prior = alpha_prior, 
  beta_prior = beta_prior,
  alpha_epsilon = alpha_epsilon, 
  beta_epsilon = beta_epsilon) %>% 
  arrange(-kl) %>% 
  mutate(
    num_true =  V1 + V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10
  ) 

kls %>% 
  ggplot(aes(x = num_true, y = kl)) + 
  geom_point() + 
  scale_x_continuous(breaks = seq(0, 10, 1))
#5, 6 * 2? 
#10 -> 22


kls %>% 
  ggplot(aes(x = kl)) + 
  geom_histogram() + 
  scale_x_continuous()

# maybe it's not the number of unique true value that matters but the unique combination of original + new?  


```

```{r}
df_count_LARGE <- tibble(
  index = all_possible_creatures$index, 
  "TF" = rep(0,  length(all_possible_creatures$index)), 
  "TT" = rep(0,  length(all_possible_creatures$index)), 
  "FT" = rep(0,  length(all_possible_creatures$index)), 
  "FF" = rep(0,  length(all_possible_creatures$index))
)

df_count_LARGE

for (i in seq(1, length(all_possible_creatures$index))){
  
  current_creature <- all_possible_creatures[i, ]
  
  for (q in seq(1, ncol(multifeature_observation))){
    
    if (multifeature_observation[[q]] == TRUE){
      if(current_creature[[q]] == TRUE){
        #TT
        df_count_LARGE[i, "TT"] = df_count_LARGE[i, "TT"] + 1
        
      }else{
        #TF
        df_count_LARGE[i, "TF"] = df_count_LARGE[i, "TF"] + 1
      }
      
    }else{
      if(current_creature[[q]] == TRUE){
        #FT
        df_count_LARGE[i, "FT"] = df_count_LARGE[i, "FT"] + 1
        
      }else{
        #FF
        df_count_LARGE[i, "FF"] = df_count_LARGE[i, "FF"] + 1
      }
      
    }
    
    
    
  }
  

  
}
# still doesn't match wtf 

df_count_LARGE %>% 
  mutate(comb_type = paste("TF", TF, "TT", TT, "FT", FT, "FF", FF, sep = "_")) %>% 
  mutate(TF_FT = TF + FT) %>% 
  group_by(TF_FT, index, comb_type) %>% 
  summarise(count_n = n()) %>% 
  left_join(kls, by = "index") %>% 
  ggplot(aes(x = index, y = kl)) + 
  geom_point() + 
  facet_wrap(~TF_FT)

```

but does it match on to the posterior predictives? 
YES
```{r}
df_count_LARGE %>% 
  mutate(comb_type = paste("TF", TF, "TT", TT, "FT", FT, "FF", FF, sep = "_")) %>% 
  mutate(TT_FF = TT + FF) %>%
    left_join(kls, by = "index") %>% 
  mutate(predictives = get_all_possible_creature_pred(
                               all_possible_creatures,
                               posterior_at_t)) %>% 
  ggplot(aes(x = index, y = predictives, color = comb_type)) + 
  geom_point() + 
  facet_wrap(~TT_FF)
  

```
## does this pattern hold with more than one observation? 

```{r}

o_at_t2<- bind_rows(multifeature_stimuli[1, ][startsWith(names(multifeature_stimuli), 
                                                           "V")], 
                    multifeature_stimuli[1, ][startsWith(names(multifeature_stimuli), 
                                                           "V")]
                    )
o_at_t2$V2[2] <- FALSE 
o_at_t2$V8[2] <- FALSE

posterior_at_t2 <- grid_apprxoimation_with_observation(
  o_at_t2, 
  grid_theta,
  grid_epsilon,  
  alpha_theta, 
  beta_theta,
  alpha_epsilon, 
  beta_epsilon)   

kls_at_t2 <- get_possible_kls(
  o_at_t2, 
  all_possible_creatures, 
  posterior_at_t2, 
  grid_theta = grid_theta, 
  grid_epsilon = grid_epsilon, 
  alpha_prior = alpha_prior, 
  beta_prior = beta_prior,
  alpha_epsilon = alpha_epsilon, 
  beta_epsilon = beta_epsilon) %>% 
  arrange(-kl) %>% 
  mutate(
    num_true =  V1 + V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10
  ) 
```

```{r}

test_kl <- function(all_possible_creatures, observations, kls, plot = TRUE){
  

  exisitng_observations_count <- lapply(observations, function(x){as.vector(x)})
  sequence_df <- tibble(stimuli = exisitng_observations_count, 
                        feature =seq(1, length(exisitng_observations_count))) %>% 
     pivot_wider(names_from = stimuli, values_from = feature) %>% 
     pivot_longer(cols = all_of(names(.)), 
                  names_to = "past_observations", 
                  values_to = "feature_position")
  
  
  
  
  unique_combination <- unique(observations %>% as.list())
  all_possible_combinations <- expand_grid(
    past_observations = as.character(unique_combination), 
    hypothetical_observation = c(TRUE, FALSE)
  ) 
  
  all_possible_combinations$count <- rep(0, nrow(all_possible_combinations))
  
  all_possible_combinations <- all_possible_combinations %>% 
    left_join(sequence_df, by = "past_observations")

  list_all_possible_combination <- lapply(seq(1, nrow(all_possible_creatures), 1), 
                                          function(x){all_possible_combinations})
  
  
for (i in 1:length(all_possible_creatures$index)){
  
  current_counter_df <- list_all_possible_combination[[i]]
  current_creature <- all_possible_creatures[i, ][startsWith(names(all_possible_creatures), 
                                                           "V")]
  
  current_scenarios <- mapply(function(x, y){c(x, y)}, 
                              exisitng_observations_count, 
                              current_creature) %>% 
    as.data.frame() %>% 
    as.list()
  
  for (j in 1:length(current_scenarios)){
    
    # figure out which two rows are relevant 
     feature_pos <- lapply(current_counter_df$feature_position, function(x){j %in% x})
     # figure out hypothetical observation 
     hypothetical_obs_pos <-  lapply(current_counter_df$hypothetical_observation,
                                     function(x){current_creature[[j]] == x})
     
     
     current_counter_df$count = current_counter_df$count + 
       (unlist(feature_pos) & unlist(hypothetical_obs_pos))
    
    
  }
  
  list_all_possible_combination[[i]] <- current_counter_df
  
 
  
  
}
  all_possible_creatures$combo <- lapply(all_possible_creatures$index,
                                         function(x){
                                        as.vector(list_all_possible_combination[[x]]$count)
                                         }
                                         )
   
  
  if(plot){
 all_possible_creatures%>% 
   mutate(combo = as.character(combo)) %>% 
  left_join(kls, by = "index") %>% 
   mutate(kl =  round(kl, 8)) %>% 
  ggplot(aes(x = index, y = kl, color = combo)) + 
  geom_point() + 
  facet_wrap(~combo)
 
 
 all_possible_creatures%>% 
   mutate(combo = as.character(combo)) %>% 
  left_join(kls, by = "index") %>% 
   mutate(kl =  round(kl, 8)) %>% 
  ggplot(aes(x = combo, y = kl, color = combo)) + 
   geom_point() + 
   scale_x_discrete(expand=c(.02, .02)) + 
   theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust =2.5)) + 
   coord_flip()
  }else{
    all_possible_creatures%>% 
   mutate(combo = as.character(combo)) %>% 
  left_join(kls, by = "index") %>% 
   mutate(kl =  round(kl, 8))
  }

}


three_feature_stimuli <- generate_creature_sequence(block_length = trials_per_block, 
  deviant_positions = deviant_positions,  # takes a vector, 
  total_feature = 3, 
  feature_theta = feature_theta, 
  feature_number = num_features_simple, 
  dissimilar_ratio = dissimilarity_ratio)

o_at_t3 <- bind_rows(three_feature_stimuli[1, ][startsWith(names(three_feature_stimuli), 
                                                           "V")], 
                    three_feature_stimuli[1, ][startsWith(names(three_feature_stimuli), 
                                                           "V")],
                     three_feature_stimuli[1, ][startsWith(names(three_feature_stimuli), 
                                                           "V")]
                    )

posterior_at_t3 <- grid_apprxoimation_with_observation(
  o_at_t3, 
  grid_theta,
  grid_epsilon,  
  alpha_theta, 
  beta_theta,
  alpha_epsilon, 
  beta_epsilon)   

all_possible_creatures_three_features <- get_possible_creatures(three_feature_stimuli[1, ][startsWith(names(three_feature_stimuli), 
                                                           "V")])
kls_at_t3 <- get_possible_kls(
  o_at_t3, 
  all_possible_creatures_three_features, 
  posterior_at_t3, 
  grid_theta = grid_theta, 
  grid_epsilon = grid_epsilon, 
  alpha_prior = alpha_prior, 
  beta_prior = beta_prior,
  alpha_epsilon = alpha_epsilon, 
  beta_epsilon = beta_epsilon) %>% 
  arrange(-kl) %>% 
  mutate(
    num_true =  V1 + V2 + V3
  ) 


test_kl(all_possible_creatures_three_features, o_at_t3, kls_at_t3)
test_kl(all_possible_creatures_three_features, o_at_t3, kls_at_t3, FALSE)
o_at_t3
#test_kl(all_possible_creatures, o_at_t2, kls_at_t2)
#test_kl(all_possible_creatures, multifeature_observation, kls)

```


values_to_calculate: 
- two ends of possible kls (sum of TF + FT)
- do interval, lay out all values 
- two ends of possible predictives 
- do interval, la out all values 
- calculate n combination in that value, (FEATURE choose SUM)
- get EIG 

```{r}
new_get_kl <- function(observations, 
                       all_possible_outcomes,
                        posterior_at_t,
                        grid_theta = grid_theta, 
                        grid_epsilon = grid_epsilon, 
                        alpha_prior = alpha_prior, 
                        beta_prior = beta_prior,
                        alpha_epsilon = alpha_epsilon, 
                        beta_epsilon = beta_epsilon){
  
  lowest_kl <- get_lowest_kl(observations, 
                       all_possible_outcomes,
                        posterior_at_t)  
  
  highest_kl <- get_highest_kl(observations, 
                       all_possible_outcomes,
                        posterior_at_t)
  
  
  
  

  
}
```


```{r}
new_get_eig <- function(observations, 
                        all_possible_outcomes, 
                        posterior_at_t, 
                        grid_theta = grid_theta, 
                        grid_epsilon = grid_epsilon, 
                        alpha_prior = alpha_prior, 
                        beta_prior = beta_prior,
                        alpha_epsilon = alpha_epsilon, 
                        beta_epsilon = beta_epsilon
){
  feature_n = ncol(observation)
  eig_df <- tibble(
    "index" = seq(0, feature_n), # sum of TF + FT combination 
    "n_condition" = choose(feature_n, seq(0, feature_n)), 
    "kl" = rep(NA_real_, feature_n + 1), 
    "post_pred" = rep(NA_real_, feature_n + 1)
  )
  
  # get kl 
  eig_df$kl <- new_get_kl(observations,
                          feature_n,
                        posterior_at_t,
                        grid_theta = grid_theta, 
                        grid_epsilon = grid_epsilon, 
                        alpha_prior = alpha_prior, 
                        beta_prior = beta_prior,
                        alpha_epsilon = alpha_epsilon, 
                        beta_epsilon = beta_epsilon)
  
  # get post_pred 
  
  # sum(kl* post_pred * n_condition)
  
  
  
                        }
```



```{r}
small_kls <- get_possible_kls(
  small_multi_observation, 
  small_possible_creatures, 
  small_posterior_at_t, 
  grid_theta = grid_theta, 
  grid_epsilon = grid_epsilon, 
  alpha_prior = alpha_prior, 
  beta_prior = beta_prior,
  alpha_epsilon = alpha_epsilon, 
  beta_epsilon = beta_epsilon) %>% 
  arrange(-kl) %>% 
  mutate(
    num_true =  V1 + V2 + V3 + V4 + V5 
  ) 

small_kls %>% 
  ggplot(aes(x = num_true, y = kl)) + 
  geom_point() + 
  scale_x_continuous(breaks = seq(0, 10, 1))

small_kls %>% 
  ggplot(aes(x = kl)) + 
  geom_histogram() 
```

```{r}
small_multi_observation
small_kls
```





```{r}
test_observation <- rep(TRUE, 5) %>% as_tibble_row(.name_repair = "unique")
test_posterior_at_t <- grid_apprxoimation_with_observation(
  test_observation, 
  grid_theta = seq(0.01, .99, .01), 
  grid_epsilon = seq(0.01, .99, .01), 
  alpha_prior = 1, 
  beta_prior = 1,
  alpha_epsilon = 10, 
  beta_epsilon = 1
)


old_get_possible_creatures <- function(test_observation){
  get_possible_creatures(test_observation)

}



cheaper_get_possible_creatures <- function(feature_n){
  
  
    flip_observation <- as.logical(1 - (current_observation) %>% 
                                   as.logical()) %>% 
    as.vector() %>% 
    as_tibble_row(.name_repair = ~ names(current_observation)) 
  
  combine_observations <- bind_rows(current_observation, flip_observation)
  
  all_possible_creatures <- combine_observations %>% 
    cross_df() %>% 
    mutate(index = row_number())
  
  
  
}


```













